# Redis

### Redis原理

1. #### Redis是什么？优缺点？

   Redis本质上是一个**Key-Value**类型的内存数据库，很像Memcached，整个数据库加载在**内存**当中操作，定期通过**异步**操作把数据库中的数据flush到硬盘上进行保存。

   因为是纯内存操作，Redis的性能相当出色，每秒可处理超过10万次的读写操作，是已知性能最快的Key-Value数据库。

   **优点：**

   1. **读写性能极高**，读110000次/s， 写81000次/s。
   2. 支持数据**持久化**，支持AOF和RDB两种持久化方式。
   3. 支持**事务**，Redis的所有操作都是原子性的。多个操作也是原子性，通过MULTI和EXEC指令抱起来。
   4. 数据**结构丰富**，支持string，hash， set， zset， list等数据结构。
   5. 支持**主从复制和读写分离**，主机会自动将数据同步到从机，可以进行读写分离。
   6. 丰富的特性 - Redis还支持publish/subscribe， 通知，key过期等特性。

   **缺点**：

   1. 数据库容量受物理内存的限制，不能用作海量数据的高性能读写， 因此Redis适合的场景局限在较小数据量的高性能操作和运算上

   2. 主句宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引起数据不一致的问题，降低了系统的可运行性

      

2. #### Redis为何这么快？

   1. 内存存储（in-memory)，没有磁盘IO上的开销。查找和操作的时间复杂度都是O(1)

   2. 单线程：单线程值得是核心网络模型中，网络请求模块使用一个线程来处理，即一个线程处理所有网络请求

   3. 非阻塞IO：使用多路复用IO技术，将epoll作为IO多路复用技术的实现，再加上Redis自身的时间处理模型将epoll中的链接，读写，关闭都转化为时间，不再网络IO上浪费过多的时间

   4. 优化的数据结构：应用层可以直接使用原生数据结构提升性能

   5. 使用底层模型不同：Redis直接构建了VM机制，因为调用系统函数会浪费时间去移动和请求

      VM机制：暂时把不经常访问的数据（冷数据）从内存交换到磁盘，从而腾出能存空间用于其他访问的热数据。通过VM实现冷热数据分离，从而避免因内存不足而造成访问速度下降的问题

      

3. #### Redis相比Memcached有哪些优势？

   1. 数据类型：Memcached所有的值都是简单的字符串，而Redis支持丰富的数据类型：string, list, set, sorted set, hash

   2. 持久化：memcache不支持数据持久存储。Redis支持数据落地持久化存储，可以将内存的数据保持在磁盘中，重启时再次加载进行使用。

   3. 集群模式：Memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。Redis提供主从同步机制，以及**Cluster集群**部署能力，能够提供高可用服务。

   4. 性能对比：Redis速度比Memcached快很多

   5. IO模型：Memcached使用多线程的非阻塞IO模式。Redis使用单线程的IO多路复用模型

   6. Redis支持**服务端的数据操作**，Memcached需要将数据按到客户端类进行类似的修改再set回去，大大增加了网络IO次数和数据体积。

      

4. #### 为什么要用Redis做缓存？

   直接在缓存上操作能够承受的请求，远远好于直接访问数据库。在硬盘上读取过程比较慢，将用户访问数据存在缓存中，操作缓存就是直接操作内存。

   

5. #### 为什么要用Redis而不用map/guava做缓存？

   缓存分为本地缓存和分布式缓存。Java中使用自带的map或guava实现的事本地缓存，最主要的特点是轻量和快速，生命周期随着jvm的销毁而结束，每个实例都需要各自保存一份缓存，缓存不具备一致性。

   使用Redis或memcached被称为分布式缓存。在多实例的情况下，各实例共用一份缓存，具有一致性。缺点是程序架构上较为复杂

   对比：

   1. Redis可以用几十个G来做缓存，Map不行，一般JVM最多分几个G的数据

   2. Redis缓存可以持久化，Map是内存对象，程序重启就会数据就会消失

   3. Redis可以实现分布式的缓存，Map只能存在创建他的程序中

   4. Redis可以处理每秒百万级的并发，是专业的缓存服务，Map只是一个普通的对象

   5. Redis缓存有过期机制，Map本身无此功能，Redis有丰富的API

   6. Redis可单独部署，多个项目之间可以共享，Map无法共享

   7. Redis有专门管理工具

      

6. #### Redis数据类型

   五种数据类型：String, Hash, Set, List, SortedSet

   三种特殊的数据类型：Bitmap(String), HyperLogLog (String), Geospatial (Sorted Set)

   1. String：普通的key- value 存储都可以归为此类。其中Value既可以是数字也可以是字符串。使用场景：常规key-value缓存应用。常规计数: 微博数，粉丝数。

   2. Hash：Hash 是一个键值(key => value)对集合。Redishash 是一个 string 类型的 field 和 value 的 映射表，hash 特别适合用于存储对象，并且可以像数据库中update一个属性一样只修改某一项属性值。

   3. Set：Set是一个无序的天然去重的集合，即Key-Set。此外还提供了交集、并集等一系列直接操作集 合的方法，对于求共同好友、共同关注什么的功能实现特别方便。

   4. List：List是一个有序可重复的集合，底层是依赖双向链表实现的，可以实现最新回复这类的功能。 

   5. SortedSet：类似于TreeSet，是Set的可排序版。此外还支持优先级排序，维护了一个score 的参数来实现。适用于排行榜和带权重的消息队列等场景。

      

7. #### Redis常用场景

   1. 缓存

   2. 排行榜

   3. 计数器

   4. 分布式会话

      集群模式下，在应用不多的情况下一般使用容器自带的session复制功能就能满足，当应用增多相对复杂 的系统中，一般都会搭建以Redis等内存数据库为中心的session服务，session不再由容器管理，而是由 session服务及内存数据库管理。

   5. 分布式锁

      在很多互联网公司中都使用了分布式技术，分布式技术带来的技术挑战是对同一个资源的并发访问，如 全局ID、减库存、秒杀等场景，并发量不大的场景可以使用数据库的悲观锁、乐观锁来实现，但在并发 量高的场合中，利用数据库锁来控制资源的并发访问是不太理想的，大大影响了数据库的性能。可以利 用Redis的setnx功能来编写分布式的锁，如果设置返回1说明获取锁成功，否则获取锁失败，实际应用 中要考虑的细节要更多。

   6. 社交网络

      点赞、踩、关注/被关注、共同好友等是社交网站的基本功能，社交网站的访问量通常来说比较大，而且 传统的关系数据库类型不适合存储这种类型的数据，Redis提供的哈希、集合等数据结构能很方便的的实 现这些功能。如在微博中的共同好友，通过Redis的set能够很方便得出。

   7. 最新列表

      Redis列表结构，LPUSH可以在列表头部插入一个内容ID作为关键字，LTRIM可用来限制列表的数量，这 样列表永远为N个ID，无需查询最新的列表，直接根据ID去到对应的内容页即可。

   8. 消息系统

      消息队列是大型网站必用中间件，如ActiveMQ、RabbitMQ、Kafka等流行的消息队列中间件，主要用 于业务解耦、流量削峰及异步处理实时性低的业务。Redis提供了发布/订阅及阻塞队列功能，能实现一 个简单的消息队列系统。另外，这个不能和专业的消息中间件相比。

      

### 持久化

1. #### 持久化机制

   1. RDB(Redis Database)：在指定的时间间隔内将内存中的数据集快照写入磁盘，它恢复时试讲快照文件直接读取到内存里

      - 优势：适合大规模的数据恢复，对数据完整性和一致性要求不高
      - 劣势：在一定间隔时间做一次备份，如果Redis意外宕机，就会丢失最后一次快照后的所有修改

   2. AOF(Append Only File)： 以日志的形式来记录每个写操作，将Redis执行过的所有写指令记录下来（读操作不记），只能追加文件但不可以改写文件，Redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。

      AOF采用文件追加方式，文件会越来越大，增加了重写机制，当AOF文件的大小超过所设定的阈值时，Redis会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集

      - 优势：

        - 每修改同步： appendfsync always 同步持久化，每次发生数据变更会被立即记录到磁盘，性能 较差但数据完整性比较好 
        - 每秒同步： appendfsync everysec 异步操作，每秒记录，如果一秒内宕机，有数据丢失 
        - 不同步： appendfsync no 从不同步

      - 劣势：相同数据集的数据而言 AOF 文件要远大于 RDB文件，恢复速度慢于RDB。 AOF 运行效率要慢于RDB ，每秒同步策略效率较好，不同步效率和 RDB相同

        

2. #### 如何选择合适的持久化方式

   1. 如果对数据不敏感，而且可以从其他地方重新生成补回的话，可以关闭持久化
   2.  如果数据比较重要，且可以承受数分钟的数据丢失，可以只使用RDB
   3. 如果是用做内存数据库，要使用Redis的持久化，建议是RDB和AOF都开启，或者定期执行bgsave 做快照备份，RDB方式更适合做数据的备份，AOF可以保证数据的不丢失。

   

3. #### Redis4.0对于持久制机制的优化

   新的AOF文件前半段是RDB格式的全量数据后半段是AOF格式的增量数据。

   优势：结合了RDB持久化和AOF持久化的优点， 由于绝大部分都是RDB格式，<u>加载速度快</u>，同时结合AOF，增量的数据以AOF方式保存了，<u>数据更少的丢失</u>。 

   劣势：<u>兼容性差</u>，一旦开启了混合持久化，在4.0之前版本都不识别该aof文件，同时由于前部分是RDB 格式，阅读性较差

   

4. #### Redis持久化数据和缓存如何扩容

   1. 如果Redis被当做缓存使用，使用一致性哈希实现动态扩容缩容

   2. 如果Redis被当做一个持久化存储实用，必须使用固定的keys-to-ndoes映射关系，节点的数量一旦确定不能变化。否则必须使用可以再运行时进行数据再平衡的一套系统——Redis集群

      

### 过期键的删除淘汰策略

1. #### Redis过期键的删除策略

   1. <u>惰性删除</u>：不会去主动删除数据，而是在访问数据的时候，再检查当前键值是否过期，如果过期则执行删除并返回 null 给客户端，如果没有过期则返回正常信息给客户端。

      - 优点：简单，不需要对过期的数据做额外的处理，只有在每次访问的时候才会检查键值是否过期。
      - 缺点：过期键删除不及时，造成了一定的空间浪费。如果数据库中有很多这种使用不到的过期键，这些键便永远不会被删除，内存永远不会释放。从而造成内存泄漏。

   2. <u>定时删除</u>：在设置某个key 的过期时间同时，我们创建一个定时器，让定时器在该过期时间到来时，立即执行对其进行删除的操作。

      - 优点：定时删除对内存是最友好的，能够保存内存的key一旦过期就能立即从内存中删除。 
      - 缺点：对CPU最不友好，在过期键比较多的时候，删除过期键会占用一部分CPU时间，对服务器的响应时间和吞吐量造成影响。

   3. <u>定期删除</u>：周期性的随机测试一批设置了过期时间的key并进行处理。测试到已过期的则进行删除。

      - 优点：可以通过限制删除操作执行的时长和频率来减少删除操作对 CPU 的影响。有效释放过期键占用的内存。
      - 缺点：难以确定删除操作执行的时长和频率。如果执行的太频繁，定期删除策略变得和定时删除策略一 样，对CPU不友好。如果执行的太少，那又和惰性删除一样了，过期键占用的内存不会及时得到释放。 另外最重要的是，在获取某个键时，如果某个键的过期时间已经到了，但是还没执行定期删除，那么就会返回这个键的值，这是业务不能忍受的错误。

      

2. #### Redis key 的过期时间和永久有效分别怎么设置

   通过expire或pexpire，客户端可以以每秒或毫秒的精度为数据库中的某个键设置生存时间。

   通过expireat和pexpireat，以秒或毫秒精度给数据库中的某个键设置过期时间，让某个键在某个时间点过期。

   

3. #### Redis内存淘汰策略

   当Redis的内存超过最大允许的内存之后，Redis会触发内存淘汰策略，删除一些不常用的数据，以保证 Redis服务器的正常运行。

   Redisv4.0前提供 6种数据淘汰策略： 

   1. volatile-lru：从已设置过期时间的数据集中（expire-set）利用LRU算法移除
   2. allkeys-lru：从数据集中移除最近最少使用的key（最常用的）
   3. volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 
   4. volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 
   5. allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 
   6. no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，新写入操作会报错。

   Redisv4.0后增加以下两种： 

   1. volatile-lfu：从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰 (LFU(Least Frequently Used)算法，也就是最频繁被访问的数据将来最有可能被访问到) 
   2. allkeys-lfu：在键空间中，移除最不经常使用的key。 

   内存淘汰策略可以通过配置文件来修改，Redis.conf对应的配置项是maxmemory-policy 修改对应的值 就行，默认是noeviction。

   

### 缓存异常

1. #### 缓存异常类型

   1. **缓存和数据库的数据不一致**

   2. **缓存雪崩**

      如果缓存在同一时间出现大规模的key失效，那么就会导致大量的请求打在了数据库上面，导致数据库压力巨大，如果在高并发的情况下，可能瞬间就会导致数据库宕机。这时候如果运维马上又重启数据库， 马上又会有新的流量把数据库打死。

      造成原因： 第一种是Redis宕机，第二种可能就是采用了相同的过期时间。 

      解决方案： 

      1. 事前： 

         均匀过期：设置不同的过期时间，让缓存失效的时间尽量均匀，避免相同的过期时间导致缓存雪 崩，造成大量数据库的访问。如把每个Key的失效时间都加个随机值， setRedis（Key，value， time + Math.random() * 10000）； ，保证数据不会在同一时间大面积失效。 

         分级缓存：第一级缓存失效的基础上，访问二级缓存，每一级缓存的失效时间都不同。 热点数据缓存永远不过期。永不过期实际包含两层意思： 物理不过期，针对热点key不设置过期时间逻辑过期，把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线 程进行缓存的构建保证Redis缓存的高可用，防止Redis宕机导致缓存雪崩的问题。可以使用 主从+ 哨兵，Redis集群来避免 Redis全盘崩溃的情况。

      2. 事中： 互斥锁：在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，比如某个key只允 许一个线程查询数据和写缓存，其他线程等待。这种方式会阻塞其他的线程，此时系统的吞吐量会 下降 使用熔断机制，限流降级。当流量达到一定的阈值，直接返回“系统拥挤”之类的提示，防止过多的请求打在数据库上将数据库击垮，至少能保证一部分用户是可以正常使用，其他用户多刷新几次也能得到结果。 

      3. 事后： 开启Redis持久化机制，尽快恢复缓存数据，一旦重启，就能从磁盘上自动加载数据恢复内存中的数据

   3. **缓存击穿**

      缓存击穿跟缓存雪崩有点类似，缓存雪崩是大规模的key失效，而缓存击穿是某个热点的key失效，大并发集中对其进行请求，就会造成大量请求读缓存没读到数据，从而导致高并发访问数据库，引起数据库压力剧增。这种现象就叫做缓存击穿。 

      1. 可以考虑热点key不设置过期时间

         1. 物理不过期，针对热点key不设置过期时间 
         2. 逻辑过期，把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线 程进行缓存的构建

      2. 考虑降低打在数据库上的请求数量

         在缓存失效后，通过互斥锁或者队列来控制读数据写缓存的线程数量，比如某个key只允许一个线程查询数据和写缓存，其他线程等待。这种方式会阻塞其他的线程，此时系统的吞吐量会下降

   4. **缓存穿透**

      缓存穿透是指用户请求的数据在缓存中不存在即没有命中，同时在数据库中也不存在，导致用户每次请 求该数据都要去数据库中查询一遍。如果有恶意攻击者不断请求系统中不存在的数据，会导致短时间大 量请求落在数据库上，造成数据库压力过大，甚至导致数据库承受不住而宕机崩溃。

      缓存穿透的关键在于在Redis中查不到key值，它和缓存击穿的根本区别在于传进来的key在Redis 中是不存在的。假如有黑客传进大量的不存在的key，那么大量的请求打在数据库上是很致命的问 题，所以在日常开发中要对参数做好校验，一些非法的参数，不可能存在的key就直接返回错误提示。

      解决方法： 

      1. 将无效的key存放进Redis中： 当出现Redis查不到数据，数据库也查不到数据的情况，我们就把这个key保存到Redis中，设置 value="null"，并设置其过期时间极短，后面再出现查询这个key的请求的时候，直接返回null，就不需 要再查询数据库了。但这种处理方式是有问题的，假如传进来的这个不存在的Key值每次都是随机的， 那存进Redis也没有意义。 
      2. 使用布隆过滤器： 如果布隆过滤器判定某个 key 不存在布隆过滤器中，那么就一定不存在，如果判定某个 key 存在，那么很大可能是存在(存在一定的误判率)。于是我们可以在缓存之前再加一个布隆过滤器，将数据库中的所有 key都存储在布隆过滤器中，在查询Redis前先去布隆过滤器查询 key 是否存在，如果不存在就直接返回，不让其访问数据库，从而避免了对底层存储系统的查询压力。 

      如何选择：针对一些恶意攻击，攻击带过来的大量key是随机，那么我们采用第一种方案就会缓存大量不存在key的数据，可以先对使用布隆过滤器方案进行过滤掉这些key。所以，针对这种key异常多、请求重复率比较低的数据，优先使用第二种方案直接过滤掉。而对于空数据的key有限的，重复率比较高的，则可优先采用第一种方式进行缓存。

      

2. #### 如何保证缓存与数据库双写时的数据一致性？

   1. **先更新数据库，后更新缓存**

      问题：并发更新数据库场景下，会将脏数据刷到缓存

   2. **先更新缓存，后更新数据库**

      问题：如果先更新缓存成功，但是数据库更新失败，则肯定会造成数据不一致

   3. **先删除缓存，后更新数据库**

      该方案也会出问题，此时来了两个请求，请求 A（更新操作） 和请求 B（查询操作） 1. 请求A进行写操作，删除缓存 2. 请求B查询发现缓存不存在 3. 请求B去数据库查询得到旧值 4. 请求B将旧值写入缓存 5. 请求A将新值写入数据库上述情况就会导致不一致的情形出现。而且，如果不采用给缓存设置过期时间策略，该数据永远都是脏数据。

      ```java
      public void write(String key,Object data){
      	Redis.delKey(key);
      	db.updateData(data);
      	Thread.sleep(1000);
      	Redis.delKey(key);
      }
      ```

      1. **延时双删**：

         1. 先淘汰缓存 
         2. 再写数据库（这两步和原来一样） 
         3. 休眠1秒，再次淘汰缓存，可以将1秒内所造成的缓存脏数据再次删除。确保读请求结束，写请求可以删除读请求造成的缓存脏数据。评估自己的项目的读数据业务逻辑的耗时，写数据的休眠时间则在读数据业务逻辑的耗时基础上，加几百ms即可。 

         如果使用的是 Mysql 的读写分离的架构的话，那么其实主从同步之间也会有时间差。此时的解决办法就是如果是对 Redis 进行填充数据的查询数据库操作，那么就强制将其指向主库进行查询。

         ![延时双删](C:\Users\chens\OneDrive\桌面\面试题\CS Notes\延时双删.PNG)

      2. **更新与读取操作进行异步串行化**：

         采用更新与读取操作进行异步串行化 异步串行化 我在系统内部维护n个内存队列，更新数据的时候，根据数据的唯一标识，将该操作路由之后，发送到其 中一个jvm内部的内存队列中（对同一数据的请求发送到同一个队列）。读取数据的时候，如果发现数据不在缓存中，并且此时队列里有更新库存的操作，那么将重新读取数据+更新缓存的操作，根据唯一标 识路由之后，也将发送到同一个jvm内部的内存队列中。然后每个队列对应一个工作线程，每个工作线 程串行地拿到对应的操作，然后一条一条的执行。 这样的话，一个数据变更的操作，先执行删除缓存，然后再去更新数据库，但是还没完成更新的时候， 如果此时一个读请求过来，读到了空的缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，排在刚才更新库的操作之后，然后同步等待缓存更新完成，再读库。 读操作去重 多个读库更新缓存的请求串在同一个队列中是没意义的，因此可以做过滤，如果发现队列中已经有了该 数据的更新缓存的请求了，那么就不用再放进去了，直接等待前面的更新操作请求完成即可，待那个队 列对应的工作线程完成了上一个操作（数据库的修改）之后，才会去执行下一个操作（读库更新缓存），此时会从数据库中读取最新的值，然后写入缓存中。 如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超 过一定时长，那么这一次直接从数据库中读取当前的旧值。（返回旧值不是又导致缓存和数据库不一致 了么？那至少可以减少这个情况发生，因为等待超时也不是每次都是，几率很小吧。这里我想的是，如果超时了就直接读旧值，这时候仅仅是读库后返回而不放缓存）

   4. **先更新数据库，后删除缓存**

      问题：数据库更新成功，但是删除缓存没有成功，此时再读取缓存的时候都是错误的数据了。

      解决方案：利用消息队列进行删除的补偿。

      1. 请求 A 先对数据库进行更新操作 
      2. 在对 Redis 进行删除操作的时候发现报错，删除失败
      3. 此时将Redis 的 key 作为消息体发送到消息队列中 
      4. 系统接收到消息队列发送的消息后再次对 Redis 进行删除操作

      缺点：会对业务代码造成大量的侵入，深深的耦合在一起

      优化：订阅 Mysql 数据库的 binlog 日志对缓存进行操作（如下图）

      <img src="C:\Users\chens\OneDrive\桌面\面试题\CS Notes\消息队列.PNG" alt="消息队列" style="zoom:67%;" />

      

3. #### 为什么是删除缓存，而不是更新缓存呢？

   很多时候，复杂点的缓存的场景，因为缓存有的时候，不单是数据库中直接取出来的值。商品详情页的系统，修改库存，只是修改了某个表的某些字段，但是要真正把这个影响的最终的库存计算出来，可能还需要从其他表查询一些数据，然后进行一些复杂的运算，才能最终计算出现在最新的库存是多少，然后才能将库存更新到缓存中去。比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并运算，才能计算出缓存最新的值的。**更新缓存的代价是很高的**。举个例子，一个缓存涉及的表的字段，在1分钟内就修改了20次，或者是100次，那么缓存更新20次，100次; 但是这个缓存在1分钟内就被读取了1次，有大量的冷数据。其实删除缓存，而不是更新缓存，就是一个惰性延迟计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算mybatis，hibernate，懒加载，思想

   

4. #### 什么是缓存预热

   系统上线后，提前将相关的缓存数据加载到缓存系统。避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题，用户直接查询事先被预热的缓存数据。 如果不进行预热，那么Redis初始状态数据为空，系统上线初期，对于高并发的流量，都会访问到数据库中， 对数据库造成流量的压力。

   解决方案： 

   1. 数据量不大的时候，工程启动的时候进行加载缓存动作

   2. 数据量大的时候，设置一个定时任务脚本，进行缓存的刷新 

   3. 数据量太大的时候，优先保证热点数据进行提前加载到缓存

      

5. #### 什么是缓存降级

   缓存降级是指缓存失效或缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或访问服务的内存数据。降级一般是有损的操作，所以尽量减少降级对于业务的影响程度。 在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级

   日志级别设置预案

   一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级； 

   警告：服务在一段时间内成功率有波动（95~100%之间），可以自动降级或人工降级并发送告警； 

   错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最 大阀值，此时可以根据情况自动降级或者人工降级； 

   严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。

[突破Java面试(27)-如何保证缓存与数据库的数据一致性-阿里云开发者社区 (aliyun.com)](https://developer.aliyun.com/article/702068)



### 线程模型

1. #### Redis为何选择单线程？

   大多数请求不会是CPU密集型的，而是IO密集型。具体到Redis的话，不考虑RDB/AOF等持久化方案，Redis是纯内存操作，执行速度是非常快的，因此不会是性能瓶颈，真正的瓶颈在于网络IO，也就是客户端和服务端的网络传输延迟，因此Redis选择了单线程的IO多路复用来实现核心的网络模型

   1. 避免上下文切换开销
   2. 避免同步机制的开销（加锁解锁的开销）
   3. 简单可维护（底层数据结构不需要是线程安全的）

   Redis4.0引入多线程处理异步任务（针对耗时的命令，通过异步化避免阻塞单线程的事件循环），Redis6.0在网络模型中实现多线程IO，所以单线程指的是6.0之前核心网络模型使用的是单线程。6.0引入多线程IO，只是用来处理网络数据读写和协议的解析， 执行命令依旧是单线程。

   

2. #### Redis6.0为何引入多线程？

   随着线上流量越来越大，Redis单线程模式会导致系统消耗很多CPU时间在网络IO上从而降低吞吐量，提升性能：

   1. 优化网络IO模块
      1. 零拷贝技术或者DPDK技术
      2. 多核优势：可以充分利用服务器CPU资源，多线程任务可以分摊Redis同步IO读写负荷
   2. 提高机器内存读写的速度（依赖于硬件发展）

   Redis作者antirez在RedisConf2019分享到：Redis6引入对性能提升至少一倍以上

   

3. #### Redis线程模型

   基于reactor模式开发了网络事件处理器，这个处理器叫做文件事件处理器（file event handler）。由于这个文件事件处理器是单线程的，所以Redis才叫做单线程模型。采用IO多路复用机制监听多个Socket，根据socket上的时间来选择对应的事件处理器来处理这个时间。

   IO多路复用是IO模型的一种，有时成为异步阻塞IO，是基于经典的Reactor设计模式设计的。多路值得是多个socket连接，复用指的是复用一个线程。多路复用：select, poll, epoll

   ![redis多路复用](C:\Users\chens\OneDrive\桌面\面试题\CS Notes\redis多路复用.PNG)

   文件事件处理器：

   1. 多个socket：socket可读时会产生一个AE_READBLE事件，socket可写时，会产生一个AE_WRITEABLE事件
   2. IO多路复用程序
   3. 文件事件分派器
   4. 事件处理器
      - 客户端要连接Redis,那么会为socket关联连接应答处理器
      - 客户端要写数据到Redis，那么会为socket关联命令请求处理器
      - 客户端要从Redis读数据，关联命令回复处理器

   IO多路复用监听着这些socket， 当发生了事件，IO多路复用将这些事件放到一个队列中，通过这个队列以有序，同步，每次一个事件的方式向文件时间分派器中传送。当事件处理器完成一个事件后，才会继续传送下一个事件

   

4. #### Redis6.0多线程的实现机制

   1. 主线程负责接收建立连接请求，获取 Socket 放入全局等待读处理队列。 
   2. 主线程处理完读事件之后，通过 RR（Round Robin）将这些连接分配给这些 IO 线程。 
   3. 主线程阻塞等待 IO 线程读取 Socket 完毕。 
   4. 主线程通过单线程的方式执行请求命令，请求数据读取并解析完成，但并不执行。 
   5. 主线程阻塞等待 IO 线程将数据回写 Socket 完毕。

   <img src="C:\Users\chens\OneDrive\桌面\面试题\CS Notes\redis多线程.PNG" alt="redis多线程" style="zoom:70%;" />

5. #### Redis6.0开启多线程后，是否会存在线程并发安全问题？

   从实现机制上看，redis多线程部分知识用来处理网络数据的读写和协议解析，实行命令仍然是单线程顺序执行。所以我们不需要去考虑控制 Key、Lua、事务，LPUSH/LPOP 等等的并发及线程安全问题。

   

6. #### Redis6.0与Memcached多线程模型的对比

   相同点：都采用了Master线程-Worker线程的模型

   不同点：Memcached执行侏罗纪也是在Woker线程里，模型更加简单，实现了真正的线程隔离。

   Redis把处理逻辑还给Master线程，虽然增加了模型复杂度，但也解决了线程并发安全等问题。

   

### 事务

1. #### Redis事务的概念

   单个Redis命令的执行是原子性的，但是Redis没有在事务上增加任何维持原子性的机制，所以Redis事务的执行不是原子性的。事务可以理解为一个打包的批量执行脚本，但批量指令并非原子化的操作，中间某条指令的失败不会导致前面已做指令的回滚，也不会造成后续的指令不做。

   1. Redis事务中如果有某一条命令执行失败，之前的命令不会回滚，其后的命令仍然会被继续执行。 鉴于这个原因，所以说Redis的事务严格意义上来说是不具备原子性的。 

   2. Redis事务中所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送 来的命令请求所打断。 

   3. 在事务开启之前，如果客户端与服务器之间出现通讯故障并导致网络断开，其后所有待执行的语句都将不会被服务器执行。然而如果网络中断事件是发生在客户端执行EXEC命令之后，那么该事务 中的所有命令都会被服务器执行。

      当使用Append-Only模式时，Redis会通过调用系统函数write将该事务内的所有写操作在本次调用中全部写入磁盘。然而如果在写入的过程中出现系统崩溃，如电源故障导致的宕机，那么此时也许只有部分数据被写入到磁盘，而另外一部分数据却已经丢失。Redis服务器会在重新启动时执行一系列必要的一致性检测，一旦发现类似问题，就会立即退出并给出相应的错误提示。此时，我们就要充分利用Redis工具包中提供的Redis-check-aof工具，该工具可以帮助我们定位到数据不一致的错误，并将已经写入的部分数据进行回滚。修复之后我们就可以再次重新启动Redis服务器了。

      

2. #### Redis事务的三个阶段

   1. multi 开启事务 
   2. 大量指令入队 
   3. exec执行事务块内命令，截止此处一个事务已经结束。 
   4. discard 取消事务 
   5. watch 监视一个或多个key，如果事务执行前key被改动，事务将打断。unwatch 取消监视。 

   事务执行过程中，如果服务端收到有EXEC、DISCARD、WATCH、MULTI之外的请求，将会把请求放入 队列中排队.

   

3. #### Redis事务相关命令

   Redis事务功能是通过MULTI、EXEC、DISCARD和WATCH 四个原语实现的 

   1. WATCH 命令是一个乐观锁，可以为 Redis 事务提供 check-and-set （CAS）行为。 可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC 命令。 

   2. MULTI命令用于开启一个事务，它总是返回OK。 MULTI执行之后，客户端可以继续向服务器发送任意多条命令，这些命令不会立即被执行，而是被放到一个队列中，当EXEC命令被调用时，所有 145 队列中的命令才会被执行。 

   3. EXEC：执行所有事务块内的命令。返回事务块内所有命令的返回值，按命令执行的先后顺序排 列。 当操作被打断时，返回空值 nil 。 通过调用DISCARD，客户端可以清空事务队列，并放弃执行事务， 并且客户端会从事务状态中退 出。 

   4. UNWATCH命令可以取消watch对所有key的监控。

      

4. #### Redis事务支持隔离性吗

   Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，Redis 的事务是总是带有隔离性的。

   

5. #### Redis为什么不支持事务回滚？

   Redis 命令只会因为错误的语法而失败，或是命令用在了错误类型的键上面，这些问题不能在入队 时发现，这也就是说，从实用性的角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发的过程中被发现，而不应该出现在生产环境中。因为不需要对回滚进行支持，所以 Redis 的内部可以保持简单且快速。

   

6. #### Redis事务其他实现

   基于Lua脚本，Redis可以保证脚本内的命令一次性、按顺序地执行， 其同时也不提供事务运行错误的回滚，执行过程中如果部分命令运行错误，剩下的命令还是会继续运行完。 

   基于中间标记变量，通过另外的标记变量来标识事务是否执行完成，读取数据时先读取该标记变量判断是否事务执行完成。但这样会需要额外写代码实现，比较繁琐。

   

### 主从、哨兵、集群

1. #### 常见使用方式

   - Redis单副本

   - Redis多副本（主从）

   - Redis Sentinel（哨兵）
   - Redis Cluster
   - Redis自研

   使用场景：

   1. 如果数据量很少，主要是承载高并发高性能的场景，比如缓存一把就几个G的话，单机足够了

   主从模式: master节点挂掉后，需要手动指定新的master，可用性不高，基本不用

   哨兵模式：master节点挂掉后，哨兵进程会主动选举新的master，可用性高，但是每个节点存储的数据是一样的，浪费内存空间。数据量不是很多，集群规模不是很大，需要自动容错容灾的时候使用。

   Redis cluster：海量数据+高并发+高可用。所有master容量总和就是Redis cluster可缓存的数据容量

   

2. #### 单副本

   采用单个Redis节点部署架构，没有备用节点实时同步数据，不提供数据持久化和备份策略，适用于数据可靠性要求不高的纯缓存业务场景

   优点：

   - 架构简单，部署方便
   - 高性价比：缓存使用时无需备用节点（单实例可用性可以用supervisor或crontab保证），也可以牺牲一个备用节点，但同时刻只由一个实例对外提供服务
   - 高性能

   缺点：

   - 不保证数据的可靠性

   - 在缓存使用，进程重启后，数据丢失，机试有备用的节点解决高可用性，但是仍然不能解决缓存预热的问题，因此不适合用于数据可靠性要求很高的业务

   - 高性能受限于单核CPU的处理能力，CPU为主要瓶颈，所以适合操作命令简单，排序，计算较少的场景，也可以考虑用memcached替代

     

3. #### 多副本

   主从（replication）部署结构，相较于单副本最大的特点就是主从实例间数据实时同步，并且提供数据持久化和备份策略。主从实例部署在不同的物理服务器上，根据公司基础环境配置，可以实现同时对外提供服务和读写分离策略

   优点：

   - 高可靠性：
     - 采用双机主备架构，能够在主库出现故障时自动进行主备切换，从库提升为主库提供服务，保证服务平稳运行；
     - 开启数据持久化功能和配置合理的备份策略，能有效 的解决数据误操作和数据异常丢失的问题；
   - 读写分离策略：从节点可以扩展主库节点的读能力，有效应对大并发量的读操作

   缺点：

   - 故障恢复复杂：如果没有RedisHA系统（需要开发），当主库节点出现故障时，需要手动将一个节点晋级为主节点，同时需要通知业务方变更配置，并且需要让其它从库节点去复制新主库节点，需人为操作

   - 主库的写能力受到单机的限制，可以考虑分片

   - 主库的存储能力受到单机的限制，可以考虑Pika

   - 原生复制的弊端在早起的版本中也会比较突出，如Redis复制中断后，Slave会发起psync，如果同步不成功，则会进行全量同步，主库执行全量备份的同时可能会造成毫秒或秒级的卡顿；又由于COW机制，导致极端情况下的主库内存溢出，程序异常退出或宕机；主库节点生成备份文件 导致服务器磁盘IO和CPU（压缩）资源消耗；发送数GB大小的备份文件导致服务器出口带宽暴增，阻塞请求，建议升级到最新版本。

     

4. #### Redis Sentinel

   主从模式下，当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预， 还会造成一段时间内服务不可用。这种方式并不推荐，实际生产中，我们优先考虑哨兵模式。这种模式下，master宕机，哨兵会自动选举 master 并将其他的 slave 指向新的 master。

   Redis Sentinel是社区版本退出的原生高可用解决方案，其部署架构主要包括两部分：Redis Sentinel集群和Redis数据集群。其中Redis Senteinel集群是由若干Sentinel节点组成的分布式集群，**可以实现故障发现，故障自动转移，配置中心和客户端通知**。Redis Sentinel的节点数量要满足2n+1个

   ![Redis哨兵](C:\Users\chens\OneDrive\桌面\面试题\CS Notes\Redis哨兵.PNG)

   优点：

   1. Redis Sentinel集群部署简单
   2. 能够解决Redis主从模式下的高可用切换问题
   3. 很方便实现Redis数据节点的线性扩展，轻松突破Redis自身单线程瓶颈，可极大满族Redis大容量或高性能的业务需求
   4. 可以实现一套Sentinel监控一组Redis数据节点或者多组数据节点

   缺点：

   1. 部署相对Redis主从模式要复杂一些

   2. 资源浪费，Redis数据节点中slave节点作为备份节点不需要提供服务

   3. Redis Sentinel主要针对Redis数据节点中的主节点高可用切换，对Redis的数据节点做失败判定分为主观下线和客观下线两种，对于Redis的从节点有对节点做主观下线操作，并不执行故障转移

   4. 不能解决读写分离问题，实现起来相对复杂

      

5. #### Redis Cluster 

   Redis 的哨兵模式基本已经可以实现高可用，读写分离 ，但是在这种模式下**每台 Redis 服务器都存储相同的数据，很浪费内存**，所以在 Redis3.0 上加入了 Cluster 集群模式，实现了分布式存储，<u>对数据进行分片</u>，也就是说每台 Redis 节点上存储不同的内容。

   Redis Cluster是社区版推出的Redis分布式集群解决方案，主要**解决Redis分布式**方面的需求，比如，当遇到**单机内存，并发和流量**等瓶颈的时候，Redis Cluster能起到很好的负载均衡的目的。 

   Redis Cluster集群节点最小配置6个节点以上（3主3从），其中主节点提供读写操作，从节点作为备用节点，不提供请求，只作为故障转移使用。 

   Redis Cluster采用虚拟槽分区，所有的键根据哈希函数映射到0～16383个整数槽内，每个节点负责维护 一部分槽以及槽所印映射的键值数据。

   ![Redis Cluster](C:\Users\chens\OneDrive\桌面\面试题\CS Notes\Redis Cluster.PNG)

   优点： 

   1. 无中心架构
   2. 数据按照slot存储分布在多个节点，节点间数据共享，可动态调整数据分布
   3. 可扩展性：可线性扩展到1000多个节点，节点可动态添加或删除
   4. 高可用性：部分节点不可用时，集群仍可用。通过增加Slave做standby数据副本，能够实现故障自动failover，节点之间通过gossip协议交换状态信息，用投票机制完成Slave到Master的角色提升；
   5. 降低运维成本，提高系统的扩展性和可用性。 

   缺点： 

   1. Client实现复杂，驱动要求实现Smart Client，缓存slots mapping信息并及时更新，提高了开发难 ，客户端的不成熟影响业务的稳定性。目前仅JedisCluster相对成熟，异常处理部分还不完善， 比如常见的“max redirect exception”。 

   2. 节点会因为某些原因发生阻塞（阻塞时间大于clutser-node-timeout），被判断下线，这种 failover是没有必要的。 

   3. 数据通过异步复制，不保证数据的强一致性。 多个业务使用同一套集群时，无法根据统计区分冷热数据，资源隔离性较差，容易出现相互影响的情况。 

   4. Slave在集群中充当“冷备”，不能缓解读压力，当然可以通过SDK的合理设计来提高Slave资源的利用率。 

   5. Key批量操作限制，如使用mset、mget目前只支持具有相同slot值的Key执行批量操作。对于映射 为不同slot值的Key由于Keys不支持跨slot查询，所以执行mset、mget、sunion等操作支持不友 好。 

   6. Key事务操作支持有限，只支持多key在同一节点上的事务操作，当多个Key分布于不同的节点上时无法使用事务功能。 

   7. Key作为数据分区的最小粒度，不能将一个很大的键值对象如hash、list等映射到不同的节点。 不支持多数据库空间，单机下的Redis可以支持到16个数据库，集群模式下只能使用1个数据库空 间，即db 0。 

   8. 复制结构只支持一层，从节点只能复制主节点，不支持嵌套树状复制结构。 

   9. 避免产生hot-key，导致主库节点成为系统的短板

   10. 避免产生big-key，导致网卡撑爆、慢查询等

   11. 重试时间应该大于cluster-node-time时间

   12. Redis Cluster不建议使用pipeline和multi-keys操作，减少max redirect产生的场景。

       

6. #### Redis 自研

   Redis自研的高可用解决方案，主要体现在配置中心，故障探测和failover的处理机制上，通常需要根据企业业务的实际线上环境来定制化

   优点：

   1. 高可靠性，高可用性
   2. 自主可控性高
   3. 贴切业务实际需求，可缩性好，兼容性好

   缺点：

   1. 实现复杂，开发成本高
   2. 需要建立配套的周边设施，如监控，域名服务，存储元数据信息的数据库
   3. 维护成本高

   ![Redis自研1](C:\Users\chens\OneDrive\桌面\面试题\CS Notes\Redis自研1.PNG)

    ![redis自研2](C:\Users\chens\OneDrive\桌面\面试题\CS Notes\redis自研2.PNG)

   

7. #### Redis高可用方案具体怎么实施？

   使用官方推荐的哨兵(sentinel)机制就能实现，当主节点出现故障时，由Sentinel自动完成故障发现和转移，并通知应用方，实现高可用性。它有四个主要功能： 

   1. **集群监控**，负责监控Redis master和slave进程是否正常工作。 

   2. **消息通知**，如果某个Redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员。 

   3. **故障转移**，如果master node挂掉了，会自动转移到slave node上。 

   4. **配置中心**，如果故障转移发生了，通知client客户端新的master地址。

      

8. #### 主从复制原理

   1. **主从架构的核心原理**

      当启动一个slave node的时候，它会发送一个PSYNC命令给master node。如果这是slave node重新连接master node，那么master node仅仅会复制给slave部分缺少的数据； 否则如果是slave node第一次连接master node，那么会触发一次full resynchronization。

      开始full resynchronization的时候，master会启动一个后台线程，开始生成一份RDB快照文件，同时还会将从客户端收到的所有写命令缓存在内存中。RDB文件生成完毕之后，master会将这个RDB发送给 slave，slave会先写入本地磁盘，然后再从本地磁盘加载到内存中。然后master会将内存中缓存的写命令发送给slave，slave也会同步这些数据。 

      slave node如果跟master node有网络故障，断开了连接，会自动重连。master如果发现有多个slave node都来重新连接，仅仅会启动一个rdb save操作，用一份数据服务所有slave node。

   2. **主从复制的断点续传**（主从复制的过程中如果因为网络原因停止复制了会怎么样？）

      支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份master node会在内存中常见一个backlog，master和slave都会保存一个replica offset还有一个master id，offset就是保存在backlog中的。如果master和slave网络连接断掉了，slave会让master从上次的 replica offset开始继续复制。但是如果没有找到对应的offset，那么就会执行一次resynchronization全量复制

   3. **无磁盘化复制**

      1. master在内存中直接创建rdb，然后发送给slave，不会在自己本地落地磁盘了 
      2. repl-diskless-sync repl-diskless-sync-delay，等待一定时长再开始复制，因为要等更多slave重新连接过来

   4. **过期key处理**

      slave不会过期key，只会等待master过期key。如果master过期了一个key，或者LRU淘汰了一个key，那么会模拟一条del命令发送给slave

      

9. #### 主从延迟导致读取到过期数据怎么处理

   1. 通过**scan**命令扫库：当Redis中的key被scan的时候，相当于访问了该key，同样也会做过期检测， 充分发挥Redis惰性删除的策略。这个方法能大大降低了脏数据读取的概率，但缺点也比较明显， 会造成一定的数据库压力，否则影响线上业务的效率。

   2. Redis加入了一个新特性来解决主从不一致导致读取到过期数据问题，增加了<u>key是否过期以及对主从库</u>的判断，如果key已过期，当前访问的master则返回null；当前访问的是从库，且执行的是只读命令也返回null

      

10. #### 主从架构数据会丢失吗

    1. 异步复制导致的数据丢失：因为master -> slave的复制是异步的，所以可能有部分数据还没复制到 slave，master就宕机了，此时这些部分数据就丢失了。 

    2. 脑裂导致的数据丢失：某个master所在机器突然脱离了正常的网络，跟其他slave机器不能连接， 但是实际上master还运行着，此时哨兵可能就会认为master宕机了，然后开启选举，将其他slave 切换成了master。这个时候，集群里就会有两个master，也就是所谓的脑裂。此时虽然某个slave 被切换成了master，但是可能client还没来得及切换到新的master，还继续写向旧master的数据可能也丢失了。因此旧master再次恢复的时候，会被作为一个slave挂到新的master上去，自己的数据会清空，重新从新的master复制数据。

       

11. #### 解决主从架构数据丢失的问题

    在Redis的配置文件里设置参数，要求至少有1个slave，数据复制和同步的延迟不能超过10秒。

    `min-slaves-to-write 1` 

    `min-slaves-max-lag 10` 

    如果说一旦所有的 slave，数据复制和同步的延迟都超过了10秒钟，那么这个时候，master就不会再接收任何请求了。 减小 min-slaves-max-lag 参数的值，这样就可以避免在发生故障时大量的数据丢失，一旦发现延迟超过了该值就不会往master中写入数据。 那么对于client，我们可以采取降级措施，将数据暂时写入本地缓存和磁盘中，在一段时间后重新写入 master来保证数据不丢失；也可以将数据写入kafka消息队列，隔一段时间去消费kafka中的数据。

    

12. #### 哨兵怎么工作的

    1. 每个Sentinel以每秒钟一次的频率向它所知的Master，Slave以及其他 Sentinel 实例发送一个 PING 命令。 

    2. 如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被当前 Sentinel 标记为主观下线。 

    3. 如果一个Master被标记为主观下线，则正在监视这个Master的所有 Sentinel 要以每秒一次的频率 确认Master的确进入了主观下线状态。 

    4. 当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认Master的确进入 了主观下线状态， 则Master会被标记为客观下线 。 

    5. 当Master被 Sentinel 标记为客观下线时，Sentinel 向下线的 Master 的所有 Slave 发送 INFO 命令 的频率会从 10 秒一次改为每秒一次 （在一般情况下， 每个 Sentinel 会以每 10 秒一次的频率向它 已知的所有Master，Slave发送 INFO 命令 ）。 

    6. 若没有足够数量的 Sentinel 同意 Master 已经下线， Master 的客观下线状态就会变成主观下线。 若 Master 重新向 Sentinel 的 PING 命令返回有效回复， Master 的主观下线状态就会被移除。 

    7. sentinel节点会与其他sentinel节点进行“沟通”，投票选举一个sentinel节点进行故障处理，在从节点中选取一个主节点，其他从节点挂载到新的主节点上自动复制新主节点的数据。

       

13. #### 故障转移时会从剩下的slave选举一个新的master，被选举为 master的标准是什么？

    如果一个master被认为odown了，而且majority哨兵都允许了主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个slave来，会考虑slave的一些信息。 

    1. 跟master断开连接的时长。 如果一个slave跟master断开连接已经超过了down-after-milliseconds的10倍，外加master宕机的时长，那么slave就被认为不适合选举为master. 

    2. slave优先级。 按照slave优先级进行排序，slave priority越低，优先级就越高 

    3. 复制offset。 如果slave priority相同，那么看replica offset，哪个slave复制了越多的数据，offset越靠后，优先 级就越高 

    4. run id 如果上面两个条件都相同，那么选择一个run id比较小的那个slave

       

14. ####  同步配置的时候其他哨兵根据什么更新自己的配置呢？

    执行切换的那个哨兵，会从要切换到的新master（salve->master）那里得到一个configuration epoch，这就是一个version号，每次切换的version号都必须是唯一的。 

    如果第一个选举出的哨兵切换失败了，那么其他哨兵，会等待failover-timeout时间，然后接替继续执行 切换，此时会重新获取一个新的configuration epoch 作为新的version号。 

    这个version号就很重要了，因为各种消息都是通过一个channel去发布和监听的，所以一个哨兵完成一 次新的切换之后，新的master配置是跟着新的version号的，其他的哨兵都是根据版本号的大小来更新 自己的master配置的。

    

15. #### 为什么Redis哨兵集群只有2个节点无法正常工作？

    哨兵集群必须部署2个以上节点。 如果两个哨兵实例，即两个Redis实例，一主一从的模式。 则Redis的配置quorum=1，表示一个哨兵认为master宕机即可认为master已宕机。 但是如果是机器1宕机了，那哨兵1和master都宕机了，虽然哨兵2知道master宕机了，但是这个时候， 需要majority大多数哨兵都是运行的，2个哨兵的majority就是2（2的majority=2，3的 majority=2，5的majority=3，4的majority=2），2个哨兵都运行着，就可以允许执行故障转移。 但此时哨兵1没了就只有1个哨兵了了，此时就没有majority来允许执行故障转移，所以故障转移不会执行。

    

16. #### Redis cluster中是如何实现数据分布的？这种方式有什么优点？

    Redis cluster有固定的16384个hash slot（哈希槽），对每个key计算CRC16值，然后对16384取模，可 以获取key对应的hash slot。 

    Redis cluster中每个master都会持有部分slot（槽），比如有3个master，那么可能每个master持有 5000多个hash slot。 

    hash slot让node的增加和移除很简单，增加一个master，就将其他master的hash slot移动部分过去， 减少一个master，就将它的hash slot移动到其他master上去。每次增加或减少master节点都是对 16384取模，而不是根据master数量，这样原本在老的master上的数据不会因master的新增或减少而 找不到。并且增加或减少master时Redis cluster移动hash slot的成本是非常低的。

    

17. #### Redis cluster节点间通信是什么机制？

    Redis cluster节点间采取gossip协议进行通信，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更之后不断地将元数据发送给其他节点让其他节点进行数据变更。 

    节点互相之间不断通信，保持整个集群所有节点的数据是完整的。 主要交换故障信息、节点的增加和移除、hash slot信息等。 

    好处：元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续，打到所有节点上去更新，有一定的延时，降低了压力

    缺点：元数据更新有延时，可能导致集群的一些操作会有一些滞后。

    

### 分布式问题

1. #### 什么是分布式锁？为什么用分布式锁？

   分布式项目开发中用到的锁，用来**控制分布式系统之间同步访问共享资源**。思路是：在整个系统提供一个全局、唯一的获取锁的“东西”，然后每个系统在需要加锁时，都去问这个“东西”拿到一把锁，这样不同的系统拿到的就可以认为是同一把锁。至于这个“东西”，可以是Redis、 Zookeeper，也可以是数据库。

   特性： 

   1. 互斥性：在任何时刻，对于同一条数据，只有一台应用可以获取到分布式锁； 

   2. 高可用性：在分布式场景下，一小部分服务器宕机不影响正常使用，这种情况就需要将提供分布式锁的服务以集群的方式部署； 

   3. 防止锁超时：如果客户端没有主动释放锁，服务器会在一段时间之后自动释放锁，防止客户端宕机或者网络不可达时产生死锁； 

   4. 独占性：加锁解锁必须由同一台服务器进行，也就是锁的持有者才可以释放锁，不能出现你加的锁， 别人给你解锁了。

      

2. #### 常见分布式锁有哪些解决方案？

   1. 基于关系型数据库：

      基于关系型数据库实现分布式锁，是依赖数据库的唯一性来实现资源锁定，比如主键和唯一索引等。 

      缺点： 

      1. 这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。 
      2. 这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。 
      3. 这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。 
      4. 这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。

   2. 基于Redis实现：

      优点： Redis 锁实现简单，理解逻辑简单，性能好，可以支撑高并发的获取、释放锁操作。 

      缺点： 

      1. Redis 容易单点故障，集群部署，并不是强一致性的，锁的不够健壮； 
      2. key 的过期时间设置多少不明确，只能根据实际情况调整； 
      3. 需要自己不断去尝试获取锁，比较消耗性能。

   3. 基于ZooKeeper：

      优点： zookeeper 天生设计定位就是分布式协调，强一致性，锁很健壮。如果获取不到锁，只需要添加一个监 听器就可以了，不用一直轮询，性能消耗较小。 

      缺点： 在高请求高并发下，系统疯狂的加锁释放锁，最后 zk 承受不住这么大的压力可能会存在宕机的风险。
      
      

3. #### Redis实现分布式锁

   1. 加锁：使用setnx来加锁，key是锁的唯一表示，按业务来决定命名

      `setnx key test`

      返回1说明key原本不存在，该线程成功得到了锁；返回0说明key已经存在，抢锁失败

   2. 解锁

      `del key`

      释放锁之后，其他线程就可以执行setnx命令来获得锁

   3. 锁超时

      锁超时知道的是：如果一个得到锁的线程在执行任务的过程中挂掉，来不及显式地释放锁，这块资源将会永远被锁住，别的线程进不来。 所以，setnx的key必须设置一个超时时间，以保证即使没有被显式释放，这把锁也要在一段时间后自动释放。setnx不支持超时参数，所以需要额外指令

      `expire key 30`

      

4. ####  分布式锁存在的问题

   1. **SETNX 和 EXPIRE 非原子性** 

      假设一个场景中，某一个线程刚执行setnx，成功得到了锁。此时setnx刚执行成功，还未来得及执行expire命令，节点就挂掉了。此时这把锁就没有设置过期时间，别的线程就再也无法获得该锁。 

      解决方案: 由于 setnx 指令本身是不支持传入超时时间的，而在Redis2.6.12版本上为 set 指令增加了可选参数, 用法如下： 

      `SET key value [EX seconds][PX milliseconds] [NX|XX]SET key value [EX seconds][PX milliseconds] [NX|XX]`

      EX second: 设置键的过期时间为second秒

      PX millisecond：设置键的过期时间为millisecond毫秒 NX：只在键不存在时，才对键进行设置操作

      XX：只在键已经存在时，才对键进行设置操作

      SET操作完成时，返回OK，否则返回nil

   2. **锁误解除**

      如果线程A成功获取到了锁，并且设置了过期时间 30 秒，但线程A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁；随后 A 执行完成，线程 A 使用 DEL 命令来释放锁，但此时线程 B 加的锁还没有执行完成，线程 A 实际释放的线程 B 加的锁。 

      解决办法： **在del释放锁之前加一个判断，验证当前的锁是不是自己加的锁。** 具体在加锁的时候把当前线程的id当做value，可生成一个 **UUID 标识**当前线程，在删除之前验证key对应的value是不是自己线程的id。 还可以使用 lua 脚本做验证标识和解锁操作。

   3. **超时解锁导致并发**

      如果线程 A 成功获取锁并设置过期时间 30 秒，但线程 A 执行时间超过了 30 秒，锁过期自动释放，此时线程 B 获取到了锁，线程 A 和线程 B 并发执行。 A、B 两个线程发生并发显然是不被允许的，一般有两种方式解决该问题： 

      1. 将过期时间设置足够长，确保代码逻辑在锁释放之前能够执行完成。 
      2. 为获取锁的线程增加**守护线程**，**为将要过期但未释放的锁增加有效时间**。

   4. **不可重入**

      当线程在持有锁的情况下再次请求加锁，如果一个锁支持一个线程多次加锁，那么这个锁就是可重入的。如果一个不可重入锁被再次加锁，由于该锁已经被持有，再次加锁会失败。Redis 可通过对锁进行重入计数，加锁时加 1，解锁时减 1，当计数归 0 时释放锁。

   5. **无法等待锁释放**

      上述命令执行都是立即返回的，如果客户端可以等待锁释放就无法使用。 

      - 可以通过客户端轮询的方式解决该问题，当未获取到锁时，等待一段时间重新获取锁，直到成功获取锁或等待超时。这种方式比较消耗服务器资源，当并发量比较大时，会影响服务器的效率
      - 另一种方式是使用 Redis 的发布订阅功能，当获取锁失败时，订阅锁释放消息，获取锁成功后释放 时，发送锁释放消息。

   https://xiaomi-info.github.io/2019/12/17/Redis-distributed-lock/

   

5. #### RedLock

   RedLock是一种算法，Redis Distributed Lock，可以实现多节点Redis的分布式锁。Redisson完成了对Redlock算法封装。

   1. 互斥访问：永远只有一个client能拿到锁
   2. 避免死锁：**最终client都能拿到锁**，不会出现死锁的情况，即使锁定资源的服务崩溃或者分区，仍然能释放锁
   3. 容错性：**只要大部分Redis节点存活（一半以上），就可以提供正常服务**

   

6. #### RedLock的原理

   假设有5个完全独立的Redis主服务器 

   1. 获取当前时间戳 
   2. client尝试按照顺序使用相同的key,value获取所有Redis服务的锁，在获取锁的过程中的获取时间比锁过期时间短很多，这是为了不要过长时间等待已经关闭的Redis服务。并且试着获取下一个 Redis实例。 

   比如：TTL为5s,设置获取锁最多用1s，所以如果一秒内无法获取锁，就放弃获取这个锁，从而尝试获取 下个锁 

   3. client通过获取所有能获取的锁后的时间减去第一步的时间，这个时间差要小于TTL时间并且至少有 3个Redis实例成功获取锁，才算真正的获取锁成功 
   4. 如果成功获取锁，则锁的真正有效时间是 TTL减去第三步的时间差的时间；比如：TTL是5s，获取所有锁用了2s,则真正锁有效时间为3s(其实应该再减去时钟漂移)
   5. 如果客户端由于某些原因获取锁失败，便会开始解锁所有Redis实例；因为可能已经获取了小于3个 锁，必须释放，否则影响其他client获取锁

   <img src="C:\Users\chens\OneDrive\桌面\面试题\CS Notes\RedLock.PNG" alt="RedLock" style="zoom:80%;" />

### 其他

1. #### Redis如何做内存优化？

   1. 控制key的数量。当使用Redis存储大量数据时，通常会存在大量键，过多的键同样会消耗大量内存。Redis本质是一个数据结构服务器，它为我们提供多种数据结构，如hash，list，set，zset 等 结构。使用Redis时不要进入一个误区，大量使用get/set这样的API，把Redis当成Memcached使用。对于存储相同的数据内容利用Redis的数据结构降低外层键的数量，也可以节省大量内存。 
   2. 缩减键值对象。降低Redis内存使用最直接的方式就是缩短key和value的长度。 key长度：如在设计键时，在完整描述业务情况下，键值越短越好。 value长度：值对象缩减比较复杂，常见需求是把业务对象序列化成二进制数组放入Redis。 首先应该在业务上精简业务对象，去掉不必要的属性避免存储无效数据。其次在序列化工具选择上，应该选择更高效的序列化工具来降低字节数组大小。 
   3. 编码优化。Redis对外提供了string,list,hash,set,zet等类型，但是Redis内部针对不同类型存在编 码的概念，所谓编码就是具体使用哪种底层数据结构来实现。编码不同将直接影响数据的内存占用和读写效率。可参考文章：https://cloud.tencent.com/developer/article/1162213

   

2. ####  如果现在有个读超高并发的系统用Redis来抗住大部分读请求， 你会怎么设计？

   如果是读高并发的话，先看读并发的数量级是多少，因为Redis单机的读QPS在万级，每秒几万没问题， 使用一主多从+哨兵集群的缓存架构来承载每秒10W+的读并发，主从复制，读写分离。 

   使用哨兵集群主要是提高缓存架构的可用性，解决单点故障问题。主库负责写，多个从库负责读，支持水平扩容，根据读请求的QPS来决定加多少个Redis从实例。如果读并发继续增加的话，只需要增加 Redis从实例就行了。 

   如果需要缓存1T+的数据，选择Redis cluster模式，每个主节点存一部分数据，假设一个master存 32G，那只需要n*32G>=1T，n个这样的master节点就可以支持1T+的海量数据的存储了。 

   Redis单主的瓶颈不在于读写的并发，而在于内存容量，即使是一主多从也是不能解决该问题，因为一主多从架构下，多个slave的数据和master的完全一样。假如master是10G那slave也只能存 10G数据。所以数据量受单主的影响。 而这个时候又需要缓存海量数据，那就必须得有多主了，并且多个主保存的数据还不能一样。 Redis官方给出的 Redis cluster 模式完美的解决了这个问题。





