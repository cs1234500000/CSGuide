## 计算机网络

1. #### 计算机网络的各层协议及作用

   OSI七层模型：物理层，数据链路层，网络层，运输层，会话层，表示层，应用层

   TCP/IP四层模型：网络接口层，网络层(IP)，运输层（TCP/UDP），应用层（TELNET,FTP,SMTP）

   五层模型：物理层，数据链路层，网络层，运输层，应用层

   

2. #### TCP，UDP的区别

   1. TCP面向连接，UDP无连接

   2. TCP可靠传输，使用流量控制和拥塞控制（面向字节流），UDP不可靠传输（面向报文）

   3. TCP有序，传输过程中可能会乱序，TCP会重排，UDP无需

   4. TCP慢，UDP快

   5. TCP一对一通信，UDP支持一对一，一对多，多对以，多对多交互通信

   6. TCP首部最小20字节，最大60字节，UDP首部开销小，仅8字节

      

3. #### TCP,UDP对应的应用场景

   1. TCP：FTP文件传输，HTTP/HTTPS，SMTP(电子邮件)，TELNET（远程终端接入）

   2. UDP：包总量较小的通讯DNS*域名转换）,SNMP（网络管理）， 视频音频等多媒体，广播通信，NFS(远程文件服务器)

      

4. #### TCP三次握手

   ![TCP三次握手](C:\Users\chens\OneDrive\桌面\面试题\CS Notes\TCP三次握手.PNG)

   第一次握手：客户端请求建立连接，向服务端发送一个同步报文（SYN=1），同时选择一个随机 数 seq = x 作为初始序列号，并进入SYN_SENT状态，等待服务器确认。 

   第二次握手：：服务端收到连接请求报文后，如果同意建立连接，则向客户端发送同步确认报文 （SYN=1，ACK=1），确认号为 ack = x + 1，同时选择一个随机数 seq = y 作为初始序列号，此时 服务器进入SYN_RECV状态。 

   第三次握手：客户端收到服务端的确认后，向服务端发送一个确认报文（ACK=1），确认号为 ack = y + 1，序列号为 seq = x + 1，客户端和服务器进入ESTABLISHED状态，完成三次握手。

   

5. #### 为什么需要三次握手而不是两次？

   1. 防止已过期的连接请求报文突然又传送到服务器，从而能产生错误和资源浪费

      知道的服务端报文到达服务器，服务器返回确认报文并进入ESTABLISHED状态，但是客户端已经CLOSED无法再接收确认报文段，导致服务器长时间单方面等待造成资源浪费

   2. 三次握手才能让双方均确认自己和对方的发送和接收能力都正常

   3. 告知对方自己的初始序列号值，并确认收到对方的初始序列号值

      

6. ####  为什么三次握手不是四次？

   三次握手已经可以确认双方的发送接收能力正常，并初始序列号得到确认，无需四次握手

   

7. ####  什么是SYN洪泛攻击

   属于DOS 攻击的一种，它利用 TCP 协议缺陷，通过发送大量的半连接请求，耗费 CPU和内存资源。 

   **原理**： 在三次握手过程中，服务器发送 [SYN/ACK] 包（第二个包）之后、收到客户端的 [ACK] 包（第 三个包）之前的 TCP 连接称为半连接（half-open connect），此时服务器处于 SYN_RECV （等待 客户端响应）状态。如果接收到客户端的 [ACK] ，则 TCP 连接成功，如果未接受到，则会不断重发请求直至成功。 SYN 攻击的攻击者在短时间内伪造大量不存在的 IP 地址，向服务器不断地发送 [SYN] 包，服务器回复 [SYN/ACK] 包，并等待客户的确认。由于源地址是不存在的，服务器需要不断的重发直至 超时。 这些伪造的 [SYN] 包将长时间占用未连接队列，影响了正常的 SYN，导致目标系统运行缓慢、网络堵塞甚至系统瘫痪。 

   **检测**：当在服务器上看到大量的半连接状态时，特别是源 IP 地址是随机的，基本上可以断定这是一次 SYN 攻击。

   **防范**： 

   1. 通过防火墙、路由器等过滤网关防护。 

   2. 通过加固 TCP/IP 协议栈防范，如增加最大半连接数，缩短超时时间。 

   3. SYN cookies技术。是对 TCP 服务器端的三次握手做一些修改，专门用来防范 SYN 洪泛攻击。

      

8. ####  三次握手阶段，最后一个ACK包丢失，会发生什么？

   服务端：

   第三次的ACK在网络中丢失，那么服务端该TCP连接的状态为SYN_RECV,并且会根据 TCP的超时重 传机制，会等待3秒、6秒、12秒后重新发送SYN+ACK包，以便客户端重新发送ACK包。 如果重发指定次数之后，仍然未收到 客户端的ACK应答，那么一段时间后，服务端自动关闭这个连 接。

   客户端：

   客户端认为这个连接已经建立，如果客户端向服务端发送数据，服务端将以RST包（Reset，标示复位， 用于异常的关闭连接）响应。此时，客户端知道第三次握手失败。

   

9. #### TCP四次挥手

   ![TCP四次挥手](C:\Users\chens\OneDrive\桌面\面试题\CS Notes\TCP四次挥手.PNG)

   第一次挥手：客户端向服务端发送<u>连接释放报文</u>（FIN=1，ACK=1），主动关闭连接，同时等待服 务端的确认。 序列号 seq = u，即客户端上次发送的报文的最后一个字节的序号 + 1 确认号 ack = k, 即服务端上次发送的报文的最后一个字节的序号 + 1 

   第二次挥手：服务端收到连接释放报文后，立即发出确认报文（ACK=1），序列号 seq = k，确认 号 ack = u + 1。 这时 TCP 连接处于**半关闭**状态，即客户端到服务端的连接已经释放了，但是服务端到客户端的连接还未释放。这表示客户端已经没有数据发送了，但是服务端可能还要给客户端发送数据。 

   第三次挥手：服务端向客户端发送连接释放报文（FIN=1，ACK=1），主动关闭连接，同时等待 A 的确认。 序列号 seq = w，即服务端上次发送的报文的最后一个字节的序号 + 1。 确认号 ack = u + 1，与第二次挥手相同，因为这段时间客户端没有发送数据 

   第四次挥手：客户端收到服务端的连接释放报文后，立即发出确认报文（ACK=1），序列号 seq = u + 1，确认号为 ack = w + 1。 此时客户端就进入了 TIME-WAIT 状态。注意客户端到 TCP 连接还没有释放，必须经过 2*MSL（最长报文段寿命）的时间后，才进入 CLOSED 状态。而服务端只要收到客户端发出的确认，就立即进入 CLOSED 状态。服务端结束 TCP 连接的时间要比客户端早一些。

   

10. #### 为什么连接的时候是三次握手关闭的时候是四次？

    服务器的ACK和FIN一般都会分开发送，从而导致多了一次。服务器在收到客户端的FIN报文段后，可能还有一些数据要传输，所以不能马上关闭连接，但是会做出应答，返回ACK报文段。

    接下来可能继续发送数据，在数据发送完后，服务器会向客户端发送FIN报文，表示数据已经发送完毕，请求关闭连接。

    

11. #### 为什么客户端的TIME-WAIT必须等待2MSL？

    1. 确保ACK报文能到达服务端，从而使服务端正常关闭连接

       第四次挥手时，客户端第四次挥手的 ACK 报文不一定会到达服务端。服务端会超时重传 FIN/ACK 报文，此时如果客户端已经断开了连接，那么就无法响应服务端的二次请求，这样服务端迟迟收不到FIN/ACK 报文的确认，就无法正常断开连接。 

       MSL 是报文段在网络上存活的最长时间。客户端等待 2MSL 时间，即「客户端 ACK 报文 1MSL 超时 + 服务端FIN 报文 1MSL 传输」，就能够收到服务端重传的 FIN/ACK 报文，然后客户端重传一 次ACK报文，并重新启动 2MSL 计时器。如此保证服务端能够正常关闭。 如果服务端重发的 FIN 没有成功地在 2MSL 时间里传给客户端，服务端则会继续超时重试直到断开 连接。

    2. 防止已失效的连接请求报文段出现在之后的连接中

       TCP 要求在 2MSL 内不使用相同的序列号。客户端在发送完最后一个 ACK 报文段后，再经过时间 2MSL，就可以保证本连接持续的时间内产生的所有报文段都从网络中消失。这样就可以使下一个连接中不会出现这种旧的连接请求报文段。或者即使收到这些过时的报文，也可以不处理它。

       

12. #### 如何已经建立了连接但是客户端出现故障了怎么办？

    通过定时器 （2小时）+ 超时重试机制（10次），尝试获取确认，直到最后会自动断开连接。 具体而言，TCP设有一个保活计时器。服务器每收到一次客户端的数据，都会重新复位这个计时器，时间通常是设置为2 小时。若 2 小时还没有收到客户端的任何数据，服务器就开始重试：每隔 75 分钟发 送一个探测报文段，若一连发送 10 个探测报文后客户端依然没有回应，那么服务器就认为连接已经断 开了。

    

13. #### TIME-WAIT状态过多会产生什么后果，怎么处理？

    服务器：短时间关闭了大量的Client连接，就会造成服务器上出现大量的TIME_WAIT连接，严重消耗着服务器的资源，此时部分客户端就会显示连接不上

    客户端：会导致端口资源被占用，因为端口就65536个，被占满就会导致无法创建新的连接

    解决方法：

    1. 服务器可以设置SO_REUSEADDR套接字选项来避免TIME_WAIT选项，此套接字选项告诉内核，即使此端口正忙（TIME_WAIT）状态，也请继续并重用它

    2. 调整系统内核参数，修改/etc/sysctl/conf文件，修改net.ipv4.tcp_tw_reuse和tcp_timestamps。

       ```java
       net.ipv4.tcp_tw_reuse = 1 //表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭；
       net.ipv4.tcp_tw_recycle = 1 //表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为 0，表示关闭。
       ```

    3. 强制关闭，发现RST包越过TIME_WAIT状态，直接进入CLOSED状态

       

14. #### TIME-WAIT是服务端的状态还是客户端的状态？

    是指主动断开连接的一方会进入的状态，一般情况下只客户端，服务器端一般不设置主动关闭连接。

    

15. #### TCP协议如何保证可靠性？

    1. 检验和：接收端可以检测出来数据是否有差错和异常，有差错就会直接丢弃TCP段重发

    2. 序列号/确认应答：序列号的作用不仅仅是应答，而且可以将接收到的数据根据序列号排序，并且去掉重复序列号的数据

    3. 超时重传：发出去的数据包在接收到确认包之间的时间，如果超过了这个时间会被认为是丢包了，需要重传。最大超时时间是动态计算的

    4. 滑动窗口：提高了报文的创书效率，避免了发送方发送过多的数据而导致接收方无法正常处理的异常

    5. 拥塞控制：在数据传输过程中，可能由于网络状态的问题造成网络拥堵，引入拥塞控制可以保证TCP可靠性的同时提高性能

    6. 流量控制：如果主机A 一直向主机B发送数据，不考虑主机B的接受能力，则可能导致主机B的接受缓冲区满了而无法再接受数据，从而会导致大量的数据丢包，引发重传机制。而在重传的过程中， 若主机B的接收缓冲区情况仍未好转，则会将大量的时间浪费在重传数据上，降低传送数据的效率。所以引入流量控制机制，主机B通过告诉主机A自己接收缓冲区的大小，来使主机A控制发送的数据量。流量控制与TCP协议报头中的窗口大小有关。

       

16. #### TCP滑动窗口

    窗口大小：不需要等待确认应答包也可以继续发送数据包的最大值。

    窗口左边：已经发送并且被确认

    窗口右边：还没有轮到的分组

    窗口里面：已经发送但是未被确认的分组+窗口内等待发送的分组。

    发送过程中窗口右移。窗口大小决定了当前TCP发送包的速率，而滑动窗口的大小取决于拥塞控制窗口和流量控制窗口两者之间的最小值

    

17. #### 拥塞控制

    ![拥塞机制](C:\Users\chens\OneDrive\桌面\面试题\CS Notes\拥塞机制.PNG)

    1. 慢开始（slow-start）

       不要一开始就发送大量的数据，由小到达逐渐增加拥塞窗口的大小

    2. 拥塞避免（congestion avoidance）

       加法增大。让拥塞窗口缓慢增长，每经过一个往返时间RTT就把发送方的拥塞窗口cwnd+1而不是加倍。让窗口按现行规律缓慢增长。

    3. 快速重传（fast retransmit）

       剔除一些不必要的拥塞报文，提高网络吞吐量。比如接收方收到一个失序的报文段后就立即发出重复确认，而不是等到自己发送数据时捎带确认。规定：发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器到期。

    4. 快速恢复（fast recovery）

       为了配合快重传。当发送方连续收到三个重复确认时，就执行乘法减小的算法， 把ssthresh门限减半，但接下来并不执行慢开始算法。因为网络出现拥塞的话就不会收到好几个重复的确认，收到三个重复确认说明网络状况还可以。

       

18. #### HTTP常见状态码

    200：服务器已成功处理了请求。 通常，这表示服务器提供了请求的网页。 

    301 ： (永久移动) 请求的网页已永久移动到新位置。 服务器返回此响应(对 GET 或 HEAD 请求的响应)时，会自动将请求者转到新位置。 302：(临时移动) 服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来进行以 后的请求。 

    400 ：客户端请求有语法错误，不能被服务器所理解。 403 ：服务器收到请求，但是拒绝提供服务。 404 ：(未找到) 服务器找不到请求的网页。 

    500： (服务器内部错误) 服务器遇到错误，无法完成请求。

    

19. #### 301和302的区别

    301表示旧地址的资源已经被永久溢出了

    302表示旧地址的资源还在，只是临时从旧地址A跳转到地址B

    重定向原因：

    1. 网站调整（网页目录结构的改变）

    2. 网页被移到新地址

    3. 网页扩展名改变（需要把.php改成.html或.shtml）

       

20. #### HTTP常用请求方式

    | 方法    | 作用                                                |
    | ------- | --------------------------------------------------- |
    | GET     | 获取资源                                            |
    | POST    | 传输实体主体                                        |
    | PUT     | 上传文件                                            |
    | DELETE  | 删除文件                                            |
    | HEAD    | 和GET类似，但只返回报文首部，不返回报文实体主题部分 |
    | PATCH   | 对资源进行部分修改                                  |
    | OPTIONS | 查询指定的URL支持的方法                             |
    | CONNECT | 要求用隧道协议连接代理                              |
    | TRACE   | 服务器会将通信路径返回给客户端                      |

    PUT, DELETE, POST, GET 增删改查

    

21. #### GET和POST区别

    使用上的区别： 

    1. GET使用URL或Cookie传参，而POST将数据放在BODY中”，这个是因为HTTP协议用法的约定。 
    2. GET方式提交的数据有长度限制，则POST的数据则可以非常大”，这个是因为它们使用的操作系统和浏览器设置的不同引起的区别。 
    3. POST比GET安全，因为数据在地址栏上不可见”，这个说法没毛病，但依然不是GET和POST本身的 区别。 

    本质区别： GET和POST最大的区别主要是GET请求是幂等性的，POST请求不是。这个是它们本质区别。 幂等性是指<u>一次和多次请求某一个资源应该具有同样的副作用</u>。简单来说意味着对同一URL的多个请求应该返回同样的结果。

    

22. #### HTTP长连接和短连接

    在HTTP/1.0中，默认使用的是短连接。也就是说，浏览器和服务器每进行一次HTTP操作，就建立一 次连接，但任务结束就中断连接。如果客户端浏览器访问的某个HTML或其他类型的 Web页中包含有其他的Web资源，如JavaScript文件、图像文件、CSS文件等；当浏览器每遇到这样一个Web资源，就会建立一个HTTP会话。 

    HTTP/1.1，默认使用长连接，用以保持连接特性。使用长连接的HTTP协议，会在响应头有加 入这行代码： Connection: keep-alive 在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这一条已经建立的连接。

    Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接要客户端和服务端都支持长连接。 HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。

    

23. #### HTTP请求报文和响应报文的格式

    请求报文格式： 1. 请求行（请求方法+URI协议+版本） 2. 请求头部 3. 空行 4. 请求主体

    ```javascript
    GET/sample.jspHTTP/1.1 请求行
    Accept:image/gif.image/jpeg, 请求头部
    Accept-Language:zh-cn
    Connection:Keep-Alive
    Host:localhost
    User-Agent:Mozila/4.0(compatible;MSIE5.01;Window NT5.0)
    Accept-Encoding:gzip,deflate
    username=jinqiao&password=1234 请求主体
    ```

    响应报文： 1. 状态行（版本+状态码+原因短语） 2. 响应首部 3. 空行 4. 响应主体

    ```html
    HTTP/1.1 200 OK
    Server:Apache Tomcat/5.0.12
    Date:Mon,6Oct2003 13:23:42 GMT
    Content-Length:112
    <html>
    <head>
    <title>HTTP响应示例<title>
    </head>
    <body>
    Hello HTTP!
    </body>
    </html>
    ```

    

24. #### HTTP1.0和1.1的区别

    1. 长连接

       HTTP 1.1支持长连接（Persistent Connection）和请求的流水线（Pipelining）处理，在 一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1.1 中默认开启 Connection： keep-alive ，一定程度上弥补了HTTP1.0每次请求都要创建连接的缺点。

    2. 缓存处理

       在HTTP1.0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准， HTTP1.1则引入了更多的缓存控制策略，可供选择的缓存头来控制缓存策略。

    3. 带宽优化及网络连接的使用

       HTTP1.0中，存在一些浪费带宽的现象，例如客户端只是需要某个 对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能，HTTP1.1则在请求头 引入了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），方便了开发者自由的选择以便于充分利用带宽和连接。

    4. 错误通知的管理

       在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。

    5. Host头处理

       在HTTP1.0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname）。但随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1.1的请求消息和响应 消息都应支持Host头域，且请求消息中如果没有Host头域会报告一个错误（400 Bad Request）

       

25. #### HTTP1.1和2.0的区别

    1. 新的二进制格式

       HTTP1.1的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认0和1的组合。基于这种考虑HTTP2.0的协议解析决定采用二进制格式，实现方便且健壮。

    2. 多路复用

       即连接共享，即每一个request都是用作连接共享机制的。一个request对应一个id， 这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据 request的id将request再归属到各自不同的服务端请求里面。

    3. 头部压缩

       HTTP1.1的头部（header）带有大量信息，而且每次都要重复发送；HTTP2.0使用 encoder来减少需要传输的header大小，通讯双方各自cache一份header fields表，既避免了重复 header的传输，又减小了需要传输的大小。

    4. 服务端推送

       服务器除了对最初请求的响应外，服务器还可以额外的向客户端推送资源，而无需 客户端明确的请求。

       

26. #### HTTP与HTTPS的区别

    |              | HTTP               | HTTPS                           |
    | ------------ | ------------------ | ------------------------------- |
    | 端口         | 80                 | 443                             |
    | 安全性       | 无加密，安全性较差 | 有加密机制，安全性较高          |
    | 资源消耗     | 较少               | 由于加密处理，资源消耗更多      |
    | 是否需要证书 | 不需要             | 需要                            |
    | 协议         | 运行在TCP协议之上  | 运行在SSL协议，SSL运行在TCP之上 |

    

27. #### HTTPS的优缺点

    优点：

    1. 安全性：
       1.  使用HTTPS协议可<u>认证用户和服务器</u>，确保数据发送到正确的客户机和服务器； 
       2. HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全，可防止数据在传输过程中不被窃取、改变，确保数据的完整性。 
       3. HTTPS是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。 

    2. SEO方面：谷歌曾在2014年8月份调整搜索引擎算法，并称“比起同等HTTP网站，采用HTTPS加密的网站在搜索结果中的排名将会更高”。

    缺点： 

    1. 在相同网络环境中，HTTPS 相比 HTTP 无论是响应时间还是耗电量都有大幅度上升。 

    2. HTTPS 的安全是有范围的，在黑客攻击、服务器劫持等情况下几乎起不到作用。 

    3. 在现有的证书机制下，中间人攻击依然有可能发生。 

    4. HTTPS 需要更多的服务器资源，也会导致成本的升高。

       

28. #### HTTP原理

    ![HTTPS加密](C:\Users\chens\OneDrive\桌面\面试题\CS Notes\HTTPS加密.PNG)

    1. 客户端请求 HTTPS 网址，然后连接到 server 的 443 端口 (HTTPS 默认端口，类似于 HTTP 的80端 口)。 

    2. 采用 HTTPS 协议的服务器必须要有一套数字 CA (Certification Authority)证书。颁发证书的同时会 产生一个私钥和公钥。私钥由服务端自己保存，不可泄漏。公钥则是附带在证书的信息中，可以公开的。证书本身也附带一个证书电子签名，这个签名用来验证证书的完整性和真实性，可以防止证书被篡改。 

    3. 服务器响应客户端请求，将证书传递给客户端，证书包含公钥和大量其他信息，比如证书颁发机构信息，公司信息和证书有效期等。 

    4. 客户端解析证书并对其进行验证。如果证书不是可信机构颁布，或者证书中的域名与实际域名不一 致，或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。 如果证书没有问题，客户端就会从服务器证书中取出服务器的公钥A。然后客户端还会生成一个随机码 KEY，并使用公钥A将其加密。 

    5. 客户端把加密后的随机码 KEY 发送给服务器，作为后面对称加密的密钥。 

    6. 服务器在收到随机码 KEY 之后会使用私钥B将其解密。经过以上这些步骤，客户端和服务器终于建 立了安全连接，完美解决了对称加密的密钥泄露问题，接下来就可以用对称加密愉快地进行通信 了。 

    7. 服务器使用密钥 (随机码 KEY)对数据进行对称加密并发送给客户端，客户端使用相同的密钥 (随机码 KEY)解密数据。 

    8. 双方使用对称加密愉快地传输所有数据。

       

29. #### 浏览器输入一个URL的过程

    1. 域名解析（域名 www.baidu.com 变为 ip 地址）。 

       浏览器搜索自己的DNS缓存（维护一张域名与IP的对应表）；若没有，则搜索操作系统的DNS 缓存（维护一张域名与IP的对应表）；若没有，则搜索操作系统的hosts文件（维护一张域名与IP 的对应表）。 

       若都没有，则找 tcp/ip 参数中设置的首选 dns 服务器，即本地 dns 服务器（递归查询），本地域名服务器查询自己的dns缓存，如果没有，则进行迭代查询。将本地dns服务器将IP返回给操作系统，同时缓存IP。 

    2. 发起 tcp 的三次握手，建立 tcp 连接。浏览器会以一个随机端口（1024-65535）向服务端的 web 程序 80 端口发起 tcp 的连接。 

    3. 建立 tcp 连接后发起 http 请求 

    4. 服务器响应 http 请求，客户端得到 html 代码。服务器 web 应用程序收到 http 请求后，就开始处理请求，处理之后就返回给浏览器 html 文件。 

    5. 浏览器解析 html 代码，并请求 html 中的资源。 

    6. 浏览器对页面进行渲染，并呈现给用户。

       

30. #### 什么是Cookie, Session?

    Cookie 是<u>服务器发送到用户浏览器并保存在本地的一小块数据</u>，它会在浏览器下次向同一服务器再发起请求时<u>被携带并发送</u>到服务器上。通常，它用于告知服务端两个请求是否来自同一浏览器，如保持用户的登录状态。Cookie 使基于无状态的 HTTP 协议记录稳定 的状态信息成为了可能。

    Cookie 主要用于以下三个方面： 

    1. 会话状态管理（如用户登录状态、购物车、游戏分数或其它需要记录的信息） 
    2. 个性化设置（如用户自定义设置、主题等） 
    3. 浏览器行为跟踪（如跟踪分析用户行为等）

    Session 代表着服务器和客户端一次会话的过程。Session 对象存储特定用户会话所需的属性及配置信息。当用户在应用程序的 Web 页之间跳转时，存储在 Session 对象中的变量将不会丢失，而是在整个用户会话中一直存在下去。当客户端关闭会话，或者 Session 超时失效时会话结束。

    

31. #### Cookie, Session如何配合

    用户第一次请求服务器的时候，服务器根据用户提交的相关信息，创建对应的 Session ，请求返回时将此 Session 的唯一标识信息 SessionID 返回给浏览器，浏览器接收到服务器返回的 SessionID 信息后， 会将此信息存入到 Cookie 中，同时 Cookie 记录此 SessionID 属于哪个域名。 

    当用户第二次访问服务器的时候，请求会自动判断此域名下是否存在 Cookie 信息，如果存在自动将 Cookie 信息也发送给服务端，服务端会从 Cookie 中获取 SessionID，再根据 SessionID 查找对应的 Session 信息，如果没有找到说明用户没有登录或者登录失效，如果找到 Session 证明用户已经登录可执行后面操作。 根据以上流程可知，SessionID 是连接 Cookie 和 Session 的一道桥梁，大部分系统也是根据此原理来验证用户登录状态。

    

32. #### Cookie, Session 区别

    1. 作用范围不同，Cookie 保存在客户端（浏览器），Session 保存在服务器端。 

    2. 存取方式的不同，Cookie 只能保存 ASCII，Session可以存任意数据类型，一般情况下我们可以在 Session中保持一些常用变量信息，比如说 UserId 等。 

    3. 有效期不同，Cookie 可设置为长时间保持，比如我们经常使用的默认登录功能，Session 一般失效时间较短，客户端关闭或者 Session 超时都会失效。 

    4. 隐私策略不同，Cookie 存储在客户端，比较容易遭到不法获取，早期有人将用户的登录名和密码存储在 Cookie 中导致信息被窃取；Session 存储在服务端，安全性相对 Cookie 要好一些。 

    5. 存储大小不同， 单个 Cookie 保存的数据不能超过 4K，Session 可存储数据远高于 Cookie

       

33. #### 如何考虑分布式Session?

    1. 客户端存储：直接将信息存储在cookie中，cookie是存储在客户端上的一小段数据，客户端通过 http协议和服务器进行cookie交互，通常用来存储一些不敏感信息 

    2. Nginx ip_hash 策略：服务端使用 Nginx 代理，每个请求按访问 IP 的 hash 分配，这样来自同一 IP 固定访问一个后台服务器，避免了在服务器 A 创建 Session，第二次分发到服务器 B 的现象。

    3. Session 复制：任何一个服务器上的 Session 发生改变（增删改），该节点会把这个 Session 的所有内容序列化，然后广播给所有其它节点。 

    4. 共享 Session：服务端无状态话，将用户的 Session 等信息使用缓存中间件（如Redis）来统一管理，保障分发到每一个服务器的响应结果都一致。（建议）

       

34. #### 什么是DDos攻击？

    DDos全称Distributed Denial of Service，分布式拒绝服务攻击。最基本的DOS攻击过程如下： 1. 客户端向服务端发送请求链接数据包。 2. 服务端向客户端发送确认数据包。 3. 客户端不向服务端发送确认数据包，服务器一直等待来自客户端的确认 DDoS则是采用分布式的方法，通过在网络上占领多台“肉鸡”，用多台计算机发起攻击。 DOS攻击现在基本没啥作用了，因为服务器的性能都很好，而且是多台服务器共同作用，1V1的模式黑客无法占上风。

    预防方法： 

    1. 减少SYN timeout时间。在握手的第三步，服务器会等待30秒-120秒的时间，减少这个等待时间就能释放更多的资源。 
    2. 限制同时打开的SYN半连接数目。

    

35. #### 什么是XXS攻击？

    XSS也称 cross-site scripting，跨站脚本。通常指的是通过利用网页开发时留下的漏洞，通过巧妙的方法注入恶意指令代码到网页，使用户加载并执行攻击者恶意制造的网页程序。比如一个存在XSS漏洞的论坛，用户发帖时就可以引入带有＜script＞标签的代码，导致恶意代码的执行。 

    预防措施有： 前端：过滤。 后端：转义，比如go自带的处理器就具有转义功能。

    

36. #### SQL注入是什么，如何避免？

    SQL 注入就是在用户输入的字符串中加入 SQL 语句，如果在设计不良的程序中忽略了检查，那么这些注入进去的 SQL 语句就会被数据库服务器误认为是正常的 SQL 语句而运行，攻击者就可以执行计划外的命令或访问未被授权的数据。 

    1. 恶意拼接查询 
    2. 利用注释执行非法命令 
    3. 传入非法参数 
    4. 添加额外条件 

    避免SQL注入的一些方法： 

    1. 限制数据库权限，给用户提供仅仅能够满足其工作的最低权限。 
    2. 对进入数据库的特殊字符（’”\尖括号&*;等）转义处理 
    3. 提供参数化查询接口，不要直接使用原生SQL。

    

37. #### 负载均衡算法有哪些？

    多台服务器以对称的方式组成一个服务器集合，每台服务器都具有等价的地位，能互相分担负载。

    1. 轮询法：将请求按照顺序轮流的分配到服务器上。大锅饭，不能发挥某些高性能服务器的优势。 

    2. 随机法：随机获取一台，和轮询类似。 

    3. 哈希法：通过ip地址哈希化来确定要选择的服务器编号。好处是,每次客户端访问的服务器都是同一 个服务器，能很好地利用session或者cookie。 

    4. 加权轮询：根据服务器性能不同加权。

       

38. 什么是Socket?

    