## 操作系统

1. #### 进程和线程的区别

   1. 进程是资源管理的基本单位，线程是CPU调度的基本单位

   2. 线程上下文切换比进程上下文切换要快的多

   3. 进程是拥有资源的一个独立单位，线程不拥有系统资源，但是可以访问隶属于进程的资源

   4. 创建和撤销进程时，系统都要为之**分配或回收系统资源**如内存空间，IO设备，OS所付出的开销显著大于创建和撤销线程时的开销，进程切换远大于线程切换的开销

      

2. #### 协程和线程的区别

   1. 线程和进程都是**同步**，而协程是**异步**

   2. 线程是抢占式，协程是非抢占式。同一时间只有一个协程拥有运行权，相当于**单线程**

   3. 一个线程可以有**多个协程**，一个进程也可以有多个协程

   4. 不被操作系统内核管理，**完全由程序控制**

   5. 协程能<u>保留上一次调用时的状态</u>

      

3. #### 并发和并行

   并发：单核处理器，切换速度足够快，表现为在一段时间内可以同时运行多个程序

   并行：多核处理器，同一时刻，有多个任务在执行

   

4. #### 进程和线程的切换

   进程切换分为两步

   1. 切换**页表**以使用新的地址空间，一旦切换上下文，处理器所有已经缓存的内存地址作废
   2. **切换内核栈和硬件上下文**

   对于线程切换，只需要第二步，不涉及虚拟地址空间的切换，因为线程所在进程的虚拟地址空间是共享的。

   

5. #### 为什么虚拟地址空间切换耗时？

   进程拥有自己的**虚拟空间地址**，把**虚拟地址转换为物理地址需要查找页表**，**页表查找是个很慢的过程**，因此通常使用Cache（TLB: translation lookaside buffer) 来缓存常用的地址映射，以加速也表查找。

   切换进程后页表也需要切换，**TLB失效，Cache命中率降低**，虚拟地址转换为物理地址就会变慢，程序运行就会变慢，而线程切换不会导致TLB失效，因此线程切换比较快

   

6. ####  进程间的通信方式有哪些？

   **管道，信号， 共享内存，信号量，消息队列，socket**

   1. 管道：

      匿名管道和命名管道。匿名管道是单向的，只能在亲缘关系的进程间通信。命名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信

   2. 信号（可以用kill -l来查看）：
      1. SIGHUP：用户从终端注销，所有已启动进程都将收到该进程。系统缺省状态下对该信号的处理是终止进程
      2. SIGINT：程序终止（CTRL+C)
      3. SIGQUIT：程序退出（CTRL+\\\\）
      4. SIGBUS SIGSEGV：进程访问非法地址
      5. SIGFPE：运算中出现致命错误，除零或数据溢出等
      6. SIGKILL：用户终止进程。kill -9
      7. SIGTERM：结束进程。kill pid
      8. SIGALRM：定时器信号
      9. SIGCLD：子进程退出信号。如果父进程没有忽略也没有处理该信号，则子进程退出后形成僵尸进程

      信号是进程间通信机制中**唯一的异步通信机制**，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。
      
      **1.执行默认操作**。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。Core 的意思是 Core Dump，也即终止进程后，通过 Core Dump 将当前进程的运行状态保存在文件里面，方便程序员事后进行分析问题在哪里。
      
      **2.捕捉信号**。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。
      
      **3.忽略信号**。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SEGSTOP`，它们用于在任何时候中断或结束某一进程。
      
   3. 共享内存：映射一段能被其他进程访问的内存，由一个进程创建，但多个进程都可以访问。是最快的IPC方式，针对其他进程间通信方式运行效率低而专门设计的，通常配合<u>信号量</u>等来使用。

   4. 信号量：计数器，用来控制多个进程对共享资源的访问。锁机制。

   5. 消息队列：消息的链接表，包括Posix和System V消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。

   6. Socket：用于不同机器间的进程通信

   优缺点：

   1. 管道速度慢，容量有限

   2. Socket任何进程间都能通讯，但速度慢

   3. 消息队列：**容量受到系统限制**，第一次读的时候，要考虑上一次没有读完的问题

   4. 信号量：不能传递复杂消息，只能用来同步

   5. 共享内存区：容易控制容量，速度快，但要保持同步**需要注意线程安全**

      

7. #### 线程间同步的方式

   **互斥量，信号量， 事件**

   1. 互斥量：协调共同对一个共享资源的单独访问而设计的。互斥对象只有一个，拥有互斥对象的线程才具有访问资源的权限

      优点：不仅仅能实现同一程序不同线程，而且可以在<u>不同程序</u>的线程之间实现资源共享

      缺点：互斥量可以命名，可以跨越进程使用，所以创建互斥量需要的资源更多。而且不能同时有多个线程/进程进行操作

   2. 信号量：为控制一个具有有限数量用户资源而设计，允许多个线程同一时刻访问统一资源，但需要限制在<u>同一时刻访问此资源的最大线程数目</u>。信号量最大资源数=1就是互斥量

      优点：适用于对Socket程序中线程的同步

      缺点：

      1. 信号量机制必须有<u>公共内存</u>，不能用于分布式操作系统
      2. 信号量机制功能强大，但使用时对信号量的操作分散， 而且难以控制，读写和维护都很困难，加重编码负担； 
      3. 核心操作P-V分散在各用户程序的代码中，不易控制和管理，一旦错误，后果严重，且不易发现和 纠正。

   3. 事件：用来通知线程有一些事件已经发生，从而启动后继任务的开始




8. #### 线程分类

   用户级线程(User Level Thread)：不依赖操作系统核心。<u>利用线程库来完成创建和管理，速度比较快</u>，操作系统内核无法感知用户级线程的存在。

   内核级线程(Kernel Level Thread)：**创建，撤销和切换**都由内核实现。

   

9. #### 临界区

   每个进程访问临界资源的程序叫做临界区。一次仅允许一个进程使用的资源叫临界资源。

   1. 一次仅允许一个进程进入

   2. 有限时间内退出

   3. 如果进程不能进入自己的临界区，应让出CPU，避免进程“忙等”

      

10. ####  什么是死锁？产生条件？

    1. 产生条件：互斥，请求与保持，不剥夺，循环等待

    2. 处理方案：死锁预防（破坏后三个条件），死锁避免（银行家算法找到安全序列），死锁检测（dfs找环），死锁解除（终止进程和资源抢占。一次终止所有或只终止一个知道取消死锁循环为止），鸵鸟策略

       

11. #### 进程调度策略？

    1. 先来先服务

       非抢占式的调度算法，按照请求的顺序进行调度。**有利于长作业，但不利于短作业**，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。另外，对 I/O 密集型进程也不利，因为这种进程每次进行 I/O 操作之后 又得重新排队。

    2. 短作业优先

       非抢占式的调度算法，按估计运行时间最短的顺序进行调度。**长作业有可能会饿死**，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

    3. **最短剩余时间优先**

       最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

    4. 时间片轮转

       将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。 

       时间片轮转算法的效率和时间片的大小有很大关系：因为进程切换都要保存进程的信息并且载入新进程的信息，如果**时间片太小，会导致进程切换得太频繁**，在进程切换上就会花过多时间。 而如果**时间片过长，那么实时性就不能得到保证**。

    5. 优先级调度 

       为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等不到调度，可以**随着时间的推移增加等待进程的优先级**。

       

12. ####  进程有哪些状态？

    创建，就绪，运行，阻塞，终止

    运行态→阻塞态：往往是由于等待外设，等待主存等资源分配或等待人工干预而引起的。 

    阻塞态→就绪态：则是等待的条件已满足，只需分配到处理器后就能运行。 

    运行态→就绪态：不是由于自身原因，而是由外界原因使运行状态的进程让出处理器，这时候就变成就绪态。例如时间片用完，或有更高优先级的进程来抢占处理器等。 

    就绪态→运行态：系统按某种策略选中就绪队列中的一个进程占用处理器，此时就变成了运行态。

    ![进程状态](C:\Users\chens\OneDrive\桌面\面试题\CS Notes\进程状态.PNG) 

    

13. ####  什么是分页？

    把内存空间划分为大小相等且固定的块，作为主存的基本单位。

    程序存储在不同的页面中，页面又离散的分布在内存中，因此需要一个页表来记录映射关系，实现页号到物理块号的映射。

    访问分页系统中内存数据需要两次：

    1. 从内存中访问**页表**，从中找到指定的物理号，加上页内偏移得到实际物理地址

    2. 根据第一次物理地址访问内存取出数据

       

14. #### 什么是分段？

    分页是为了提高内存利用率，而分段是为了满足程序员在编写代码的时候的一些逻辑需求(比如数据共享，数据保护，动态链接等)。 分段内存管理当中，地址是二维的，**一维是段号，二维是段内地址**；其中每个段的长度是不一样的，而且每个段内部都是从0开始编址的。由于分段管理中，每个段内部是连续内存分配，但是段和段之间是离散分配的，因此也存在一个逻辑地址到物理地址的映射关系，相应的就是段表机制。

    

15. #### 分页和分段有什么区别

    1. 分页对程序员是透明的，但是分段需要程序员显式划分每个段。 
    2. 分页的地址空间是一维地址空间，分段是二维的。 
    3. 页的大小不可变，段的大小可以动态改变。 
    4. 分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。

    

16. #### 什么是交换空间

    操作系统把物理内存(physical RAM)分成一块一块的小内存，每一块内存被称为页(page)。当内存资源不足时，Linux把某些页的内容转移至硬盘上的一块空间上，以释放内存空间。

    硬盘上的那块空间叫做交换空间(swap space),而这一过程被称为交换(swapping)。物理内存和交换空间的总容量就是虚拟内存的可用容量。 

    用途： 物理内存不足时一些不常用的页可以被交换出去，腾给系统。 程序启动时很多内存页被用来初始化，之后便不再需要，可以交换出去。

    

17. #### 物理地址，逻辑地址，有效地址，线性地址，虚拟地址

    **物理地址**：内存中真正的地址，具有唯一性。不管哪种地址，最终都会映射为物理地址。 在实模式下，段基址 + 段内偏移经过地址加法器的处理，经过地址总线传输，最终也会转换为物理地址 。 

    **线性地址：**保护模式下，段基址 + 段内偏移，不过此时的段基址不能称为真正的地址，而是会被称作为一个选择子的东西，选择子就是个索引，相当于数组的下标，通过这个索引能够在 GDT 中找到相应的段描述符，段描述符记录了段的起始、段的大小等信息，这样便得到了基地址。如果此时没有开启内存分页功能，那么这个线性地址可以直接当做物理地址来使用，直接访问内存。

    **虚拟地址：**开启了分页功能的线性地址就是虚拟地址 

    **有效地址/逻辑地址：**不论在实模式还是保护模式下的**段内偏移地址**

    

18. #### 页面替换算法 

    ![页面替换算法](C:\Users\chens\OneDrive\桌面\面试题\CS Notes\页面替换算法.PNG)

    最好的算法是**老化算法**和**WSClock**算法。他们分别是基于 LRU 和工作集算法。他们都具有良好的性能并且能够被有效的实现。

    

19. #### 缓冲区溢出是什么？危害？

    计算机向缓冲区填充数据时超出了缓冲区本身的容量，溢出的数据覆盖在合法数据上

    1. 程序崩溃，拒绝服务
    2. 跳转并执行一段恶意代码

    溢出原因：程序中没有仔细检查用户输入

    

20. #### 虚拟内存

    虚拟内存就是说，让物理内存扩充成更大的<u>逻辑内存</u>，从而让程序获得更多的可用内存。虚拟内存使用<u>部分加载</u>的技术，让一个进程或者资源的某些页面加载进内存，从而能够加载更多的进程，甚至能加载比内存大的进程，这样看起来好像内存变大了，这部分内存其实包含了磁盘或者硬盘，并且就叫做虚拟内存。

    - 程序可以使用一系列相邻的虚拟地址来访问**物理内存中不相邻**的大内存缓冲区。
    - 程序可以使用一系列虚拟地址来访问**大于可用物理内存的内存缓冲区**。当物理内存的供应量变小时，内存管理器会将物理内存页（通常大小为 4 KB）保存到磁盘文件。数据或代码页会根据需要在物理内存与磁盘之间移动。
    - **不同进程使用的虚拟地址彼此隔离**。一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。

    

21. #### 虚拟内存的实现方式

    1. 请求分页存储管理

    2. 请求分段存储管理

    3. 请求段页式存储管理 

       

22. #### IO多路复用

    IO多路复用是指**内核**一旦发现进程指定的**一个或者多个IO条件准备读取**，它就通知该进程。

    IO多路复用适用如下场合： 

    1. 当客户处理多个描述字时（一般是交互式输入和网络套接口），必须使用I/O复用。 

    2. 当一个客户同时处理多个套接口时，而这种情况是可能的，但很少出现。 

    3. 如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I/O复用。 

    4. 如果一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用。 

    5. 如果一个服务器要处理多个服务或多个协议，一般要使用I/O复用。 

    6. 与多进程和多线程技术相比，I/O多路复用技术的最大优势是系统开销小，系统不必创建进程/线程，也不必维护这些进程/线程，从而大大减小了系统的开销。

       

23. #### 硬链接和软连接

    硬链接：就是在目录下创建一个条目，记录着文件名与 inode 编号，这个 inode 就是源文件的 inode 。删除任意一个条目，文件还是存在，只要引用数量不为 0 。但是硬链接有限制，它不能跨越文件系统，也不能对目录进行链接。 

    符号链接文件保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 Windows 的快捷方式。当源文件被删除了，链接文件就打不开了。因为记录的是路径，所以可以为目录建立符号链接。

    

24. #### 中断的处理过程

    1. 保护现场：将当前执行程序的相关数据保存在寄存器中，然后入栈。 
    2. 开中断：以便执行中断时能响应较高级别的中断请求。 
    3. 中断处理 
    4. 关中断：保证恢复现场时不被新中断打扰 
    5. 恢复现场：从堆栈中按序取出程序数据，恢复中断前的执行状态。

    

25. #### 中断和轮询有什么区别？

    1. 轮询：CPU对特定设备轮流询问。效率低等待时间长，CPU利用率不高

    2. 中断：通过**特定事件提醒CPU**。容易遗漏问题，CPU利用率不高

       

26. #### 用户态和内核态是如何切换的

    1. 首先用户程序会调用 glibc 库，glibc 是一个标准库，同时也是一套核心库，库中定义了很多关键 API。 

    2. glibc 库知道针对不同体系结构调用系统调用的正确方法，它会根据体系结构应用程序的二进制接口设置用户进程传递的参数，来准备系统调用。 

    3. 然后，glibc 库调用软件中断指令(SWI) ，这个指令通过更新 CPSR 寄存器将模式改为**超级用户模式**，然后跳转到地址 0x08 处。 

    4. 到目前为止，整个过程仍处于用户态下，在执行 SWI 指令后，允许进程执行内核代码，MMU 现在允许内核虚拟内存访问从地址 0x08 开始，进程执行加载并跳转到中断处理程序，这个程序就是 ARM 中的 vector_swi()

    5. 在 vector_swi() 处，从 SWI 指令中提取系统调用号 SCNO，然后使用 SCNO 作为系统调用表 sys_call_table 的索引，调转到系统调用函数。 

    6. 执行系统调用完成后，将还原用户模式寄存器，然后再以用户模式执行

       

27. #### UNIX常见的IO模型

    对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段： 

    1. 等待数据准备就绪 (Waiting for the data to be ready) 
    2. 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process) 正式因为这两个阶段

    linux系统产生了下面五种网络模式的方案： 

    1. 阻塞式IO模型(blocking IO model) 

       当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来），而数据被拷贝到操作系统内核的缓冲区中是需要一个过程的，这个过程需要等待。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户空间的缓冲区以后，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。

    2. 非阻塞式IO模型(noblocking IO model) 

       当用户进程调用了recvfrom这个系统调用，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个EWOULDBLOCK error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个EWOULDBLOCK error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户空间缓冲区，然后返回。

       可以看到，I/O 操作函数将不断的测试数据是否已经准备好，如果没有准备好，继续轮询，直到数据准备好为止。整个 I/O 请求的过程中，虽然用户线程每次发起 I/O 请求后可以立即返回，但是为了等到数据，仍需要不断地轮询、重复请求，消耗了大量的 CPU 的资源。

       所以，non blocking IO的特点是用户进程需要不断的主动询问kernel数据好了没有：

       - 等待数据准备就绪 (Waiting for the data to be ready) 「非阻塞」
       - 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process) 「阻塞」

    3. **IO复用式**IO模型(IO multiplexing model) 

       这个图和blocking IO的图其实并没有太大的不同，事实上因为IO多路复用多了添加监视 socket，以及调用 select 函数的额外操作，效率还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，使用 select 以后最大的优势是用户可以在一个线程内同时处理多个 socket 的 I/O 请求。用户可以注册多个 socket，然后不断地调用 select 读取被激活的 socket，即可达到在同一个线程内同时处理多个 I/O 请求的目的。而在同步阻塞模型中，必须通过多线程的方式才能达到这个目的。所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是**在于能处理更多的连接**。）

       在IO multiplexing Model中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。

       因此对于IO多路复用模型来说： 

       1. 等待数据准备就绪 (Waiting for the data to be ready) 「阻塞」
       2. 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process) 「阻塞」

    4. 异步IO式IO模型(asynchronous IO model) 

       用户进程发起aio_read调用之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它发现一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。

       异步 I/O 模型使用了 Proactor 设计模式实现了这一机制。

       因此对异步IO模型来说：

       - 等待数据准备就绪 (Waiting for the data to be ready) 「非阻塞」
       - 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process) 「非阻塞」

    5. **信号驱动式**IO模型(signal-driven IO model) 

    

28. #### select, poll, epoll区别

    都是 IO 多路复用的机制。I/O 多路复用就是通过一种机制监视多个描述符， 一旦某个描述符就绪（读就绪或者写就绪），就通知程序进行相应的读写操作。但 select， poll，epoll 本质上都是同步 I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说读写过程是阻塞的，而异步 I/O 则无需自己负责进行读写，异步 I/O 的实现会负责把数据从内核拷贝到用户空间。

    1. select：时间复杂度O(n)

       仅仅知道有IO事件发生，但并不知道是哪几个流，只能**无差别轮询所有流**，找出能读出数据或写入数据的流，并对其进行操作。

    2. poll：时间复杂度O(n)

       将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态。

       与select相比没有**最大连接数的限制**，原因是基于**链表**来存储的

    3. epoll：时间复杂度O(1)

       epoll会把**哪个流**发生了怎样的IO**事件**通知我们，事件驱动。
       
       ```c
       int s = socket(AF_INET, SOCK_STREAM, 0);   
       bind(s, ...)
       listen(s, ...)
        
       int epfd = epoll_create(...);
       epoll_ctl(epfd, ...); //将所有需要监听的socket添加到epfd中
        
       while(1){
           int n = epoll_wait(...)
           for(接收到数据的socket){
               //处理
           }
       }
       ```
       
        epoll 内部又涉及出了一套复杂的数据结构，包括一棵红黑树和一个就绪链表（以及一个epollwait等待队列）。全部都工作在内核态。通过红黑树，高效地管理海量的连接。在数据到来的时候，不断地将数据 Ready 的socket 放到就绪链表中。
       
       ![epoll](C:\Users\chens\OneDrive\桌面\面试题\CS Notes\epoll.jpg)
       
       ![epoll2](C:\Users\chens\OneDrive\桌面\面试题\CS Notes\epoll2.jpg)
    
    select/poll把fd的监听列表放在**用户空间**，由用户空间管理，导致在用户空间和内核空间之间频繁重复拷贝大量fd；epoll在**内核建立fd监听列表（实际是红黑树）**，每次通过epoll_ctl增删改即可。
    
    select/poll每当有fd内核事件时，都唤醒当前进程，然后遍历监听列表全部fd，检查所有就绪fd并返回；epoll在有fd内核事件时，通过回调把该fd放到就绪队列中，只需返回该就绪队列即可，**不需要每次遍历全部监听fd**。
    
    
    
29. #### Reactor 和 Proactor模型

    #### Reactor 

    首先来回想一下普通函数调用的机制：程序调用某函数，函数执行，程序等待，函数将结果和控制权返回给程序，程序继续处理。Reactor 释义“反应堆”，是一种事件驱动机制。和普通函数调用的不同之处在于：应用程序不是主动的调用某个 API 完成处理，而是恰恰相反，Reactor 逆置了事件处理流程，应用程序需要提供相应的接口并注册到 Reactor 上，如果相应的时间发生，Reactor 将主动调用应用程序注册的接口，这些接口又称为“回调函数”。

    ![img](https://static001.geekbang.org/infoq/0b/0beaff5abeb3955bfeacddf51870329e.png)

    Reactor 模式是处理并发 I/O 比较常见的一种模式，用于同步 I/O，中心思想是将所有要处理的 I/O 事件注册到一个中心 I/O 多路复用器上，同时主线程/进程阻塞在多路复用器上；一旦有 I/O 事件到来或是准备就绪(文件描述符或 socket 可读、写)，多路复用器返回并将事先注册的相应 I/O 事件分发到对应的处理器中。Reactor 模型有三个重要的组件：

    - 多路复用器：由操作系统提供，在 linux 上一般是 select, poll, epoll 等系统调用。
    - 事件分发器：将多路复用器中返回的就绪事件分到对应的处理函数中。
    - 事件处理器：负责处理特定事件的处理函数。

    ![img](https://static001.geekbang.org/infoq/d8/d8aab0fa97d907fe6d92c0739c007301.png)

    具体流程如下：

    1. 注册读就绪事件和相应的事件处理器；
    2. 事件分离器等待事件；
    3. 事件到来，激活分离器，分离器调用事件对应的处理器；
    4. 事件处理器完成实际的读操作，处理读到的数据，注册新的事件，然后返还控制权。

​	Reactor 模式是编写高性能网络服务器的必备技术之一，它具有如下的优点：

- 响应快，不必为单个同步时间所阻塞，虽然 Reactor 本身依然是同步的；
- 编程相对简单，可以最大程度的避免复杂的多线程及同步问题，并且避免了多线程/进程的切换开销；
- 可扩展性，可以方便的通过增加 Reactor 实例个数来充分利用 CPU 资源；
- 可复用性，reactor 框架本身与具体事件处理逻辑无关，具有很高的复用性；



Reactor 模型开发效率上比起直接使用 IO 复用要高，它通常是单线程的，设计目标是希望单线程使用一颗 CPU 的全部资源，但也有附带优点，即每个事件处理中很多时候可以不考虑共享资源的互斥访问。可是缺点也是明显的，现在的硬件发展，已经不再遵循摩尔定律，CPU 的频率受制于材料的限制不再有大的提升，而改为是从核数的增加上提升能力，当程序需要使用多核资源时，Reactor 模型就会悲剧, 为什么呢？

如果程序业务很简单，例如只是简单的访问一些提供了并发访问的服务，就可以直接开启多个反应堆，每个反应堆对应一颗 CPU 核心，这些反应堆上跑的请求互不相关，这是完全可以利用多核的。例如 Nginx 这样的 http 静态服务器。

#### Proactor

![img](https://static001.geekbang.org/infoq/ea/eaa9f387094235fa32f2140d926ba8a6.png)



![img](https://static001.geekbang.org/infoq/fd/fda6735da64066e49e2cacfe3e3a125b.png)

具体流程如下：

1. 处理器发起异步操作，并关注 I/O 完成事件
2. 事件分离器等待操作完成事件
3. 分离器等待过程中，内核并行执行实际的 I/O 操作，并将结果数据存入用户自定义缓冲区，最后通知事件分离器读操作完成
4. I/O 完成后，通过事件分离器呼唤处理器
5. 事件处理器处理用户自定义缓冲区中的数据



从上面的处理流程，我们可以发现 proactor 模型最大的特点就是 Proactor 最大的特点是使用异步 I/O。所有的 I/O 操作都交由系统提供的异步 I/O 接口去执行。工作线程仅仅负责业务逻辑。在 Proactor 中，用户函数启动一个异步的文件操作。同时将这个操作注册到多路复用器上。多路复用器并不关心文件是否可读或可写而是关心这个异步读操作是否完成。异步操作是操作系统完成，用户程序不需要关心。多路复用器等待直到有完成通知到来。当操作系统完成了读文件操作——将读到的数据复制到了用户先前提供的缓冲区之后，通知多路复用器相关操作已完成。多路复用器再调用相应的处理程序，处理数据。

Proactor 增加了编程的复杂度，但给工作线程带来了更高的效率。Proactor 可以在系统态将读写优化，利用 I/O 并行能力，提供一个高性能单线程模型。在 windows 上，由于没有 epoll 这样的机制，因此提供了 IOCP 来支持高并发， 由于操作系统做了较好的优化，windows 较常采用 Proactor 的模型利用完成端口来实现服务器。在 linux 上，在 2.6 内核出现了 aio 接口，但 aio 实际效果并不理想，它的出现，主要是解决 poll 性能不佳的问题，但实际上经过测试，epoll 的性能高于 poll+aio，并且 aio 不能处理 accept，因此 linux 主要还是以 Reactor 模型为主。

在不使用操作系统提供的异步 I/O 接口的情况下，还可以使用 Reactor 来模拟 Proactor，差别是：使用异步接口可以利用系统提供的读写并行能力，而在模拟的情况下，这需要在用户态实现。具体的做法只需要这样：

1. 注册读事件（同时再提供一段缓冲区）
2. 事件分离器等待可读事件
3. 事件到来，激活分离器，分离器（立即读数据，写缓冲区）调用事件处理器
4. 事件处理器处理数据，删除事件(需要再用异步接口注册)

