## 操作系统

1. #### 进程和线程的区别

   1. 进程是资源管理的基本单位，线程是CPU调度的基本单位

   2. 线程上下文切换比进程上下文切换要快的多

   3. 进程是拥有资源的一个独立单位，线程不拥有系统资源，但是可以访问隶属于进程的资源

   4. 创建和撤销进程时，系统都要为之分配或回收系统资源如内存空间，IO设备，OS所付出的开销显著大于创建和撤销线程时的开销，进程切换远大于线程切换的开销

      

2. #### 协程和线程的区别

   1. 线程和进程都是同步，而协程是异步

   2. 线程是抢占式，协程是非抢占式。同一时间只有一个协程拥有运行权，相当于单线程

   3. 一个线程可以有多个协程，一个进程也可以有多个协程

   4. 不被操作系统内核管理，完全由程序控制

   5. 协程能保留上一次调用时的状态

      

3. #### 并发和并行

   并发：单核处理器，切换速度足够快，表现为在一段时间内可以同时运行多个程序

   并行：多核处理器，同一时刻，有多个任务在执行

   

4. #### 进程和线程的切换

   进程切换分为两步

   1. 切换页表以使用新的地址空间，一旦切换上下文，处理器所有已经缓存的内存地址作废
   2. 切换内核栈和硬件上下文

   对于线程切换，只需要第二步，不涉及虚拟地址空间的切换，因为线程所在进程的虚拟地址空间是共享的。

   

5. #### 为什么虚拟地址空间切换耗时？

   进程拥有自己的虚拟空间地址，把虚拟地址转换为物理地址需要查找页表，页表查找是个很慢的过程，因此通常使用Cache（TLB: translation lookaside buffer) 来缓存常用的地址映射，以加速也表查找。

   切换进程后页表也需要切换，TLB失效，Cache命中率降低，虚拟地址转换为物理地址就会变慢，程序运行就会变慢，而线程切换不会导致TLB失效，因此线程切换比较快

6. ####  进程间的通信方式有哪些？

   1. 管道：

      匿名管道和命名管道。匿名管道是单向的，只能在亲缘关系的进程间通信。命名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信

   2. 信号：
      1. SIGHUP：用户从终端注销，所有已启动进程都将收到该进程。系统缺省状态下对该信号的处理是终止进程
      2. SIGINT：程序终止（CTRL+C)
      3. SIGQUIT：程序退出（CTRL+\\\\）
      4. SIGBUS SIGSEGV：进程访问非法地址
      5. SIGFPE：运算中出现致命错误，除零或数据溢出等
      6. SIGKILL：用户终止进程。kill -9
      7. SIGTERM：结束进程。kill pid
      8. SIGALRM：定时器信号
      9. SIGCLD：子进程退出信号。如果父进程没有忽略也没有处理该信号，则子进程退出后形成僵尸进程

   3. 信号量：计数器，用来控制多个进程对共享资源的访问。锁机制。
   4. 消息队列：消息的链接表，包括Posix和System V消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。
   5. 共享内存：映射一段能被其他进程访问的内存，由一个进程创建，但多个进程都可以访问。是最快的IPC方式，针对其他进程间通信方式运行效率低而专门设计的，通常配合<u>信号量</u>等来使用。
   6. Socket：用于不同机器间的进程通信

   优缺点：

   1. 管道速度慢，容量有限

   2. Socket任何进程间都能通讯，但速度慢

   3. 消息队列：容量受到系统限制，第一次读的时候，要考虑上一次没有读完的问题

   4. 信号量：不能传递复杂消息，只能用来同步

   5. 共享内存区：容易控制容量，速度快，但要保持同步需要注意线程安全

      

7. #### 进程间同步的方式

   1. 临界区：对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问

      缺点：只能用来同步<u>本进程</u>内的线程，而不能从来同步多个进程中的线程	

   2. 互斥量：协调共同对一个共享资源的单独访问而设计的。互斥对象只有一个，拥有互斥对象的线程才具有访问资源的权限

      优点：不仅仅能实现同一程序不同线程，而且可以在<u>不同程序</u>的线程之间实现资源共享

      缺点：互斥量可以命名，可以跨越进程使用，所以创建互斥量需要的资源更多。而且不能同时有多个线程/进程进行操作

   3. 信号量：为控制一个具有有限数量用户资源而设计，允许多个线程同一时刻访问统一资源，但需要限制在<u>同一时刻访问此资源的最大线程数目</u>。信号量最大资源数=1就是互斥量

      优点：适用于对Socket程序中线程的同步

      缺点：

      1. 信号量机制必须有<u>公共内存</u>，不能用于分布式操作系统
      2. 信号量机制功能强大，但使用时对信号量的操作分散， 而且难以控制，读写和维护都很困难，加重编码负担； 
      3. 核心操作P-V分散在各用户程序的代码中，不易控制和管理，一旦错误，后果严重，且不易发现和 纠正。

   4. 事件：用来通知线程有一些事件已经发生，从而启动后继任务的开始

      

8. #### 线程间同步的方式？

   同上。临界区，互斥量，信号量，事件。其中互斥量，信号量，事件都可以被跨越进程使用。

   

9. #### 线程分类

   用户级线程(User Level Thread)：不依赖操作系统核心。利用线程库来完成创建和管理，速度比较快，操作系统内核无法感知用户级线程的存在。

   内核级线程(Kernel Level Thread)：创建，撤销和切换都由内核实现。

   

10. #### 临界区

    每个进程访问临界资源的程序叫做临界区。一次仅允许一个进程使用的资源叫临界资源。

    1. 一次仅允许一个进程进入

    2. 有限时间内推出

    3. 如果进程不能进入自己的临界区，应让出CPU，避免进程“忙等”

       

11. ####  什么是死锁？产生条件？

    1. 产生条件：互斥，请求与保持，不剥夺，循环等待

    2. 处理方案：死锁预防（破坏后三个条件），死锁避免（找到安全序列，银行家算法），死锁检测（dfs找环），死锁解除（终止进程和资源抢占。一次终止所有或只终止一个知道取消死锁循环为止），鸵鸟策略

       

12. #### 进程调度策略？

    1. 先来先服务

       非抢占式的调度算法，按照请求的顺序进行调度。有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。另外，对 I/O 密集型进程也不利，因为这种进程每次进行 I/O 操作之后 又得重新排队。

    2. 短作业优先

       非抢占式的调度算法，按估计运行时间最短的顺序进行调度。长作业有可能会饿 死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调 度。

    3. 最短剩余时间优先

       最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的 作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂 起当前进程，运行新的进程。否则新的进程等待。

    4. 时间片轮转

       将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。 

       时间片轮转算法的效率和时间片的大小有很大关系：因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。 而如果时间片过长，那么实时性就不能得到保证。

    5. 优先级调度 

       为每个进程分配一个优先级，按优先级进行调度。为了防止低优先级的进程永远等 不到调度，可以随着时间的推移增加等待进程的优先级。

       

13. ####  进程有哪些状态？

    创建，就绪，运行，终止，阻塞

    运行态→阻塞态：往往是由于等待外设，等待主存等资源分配或等待人工干预而引起的。 

    阻塞态→就绪态：则是等待的条件已满足，只需分配到处理器后就能运行。 

    运行态→就绪态：不是由于自身原因，而是由外界原因使运行状态的进程让出处理器，这时候就变成就绪态。例如时间片用完，或有更高优先级的进程来抢占处理器等。 

    就绪态→运行态：系统按某种策略选中就绪队列中的一个进程占用处理器，此时就变成了运行态。

    ![进程状态](C:\Users\chens\OneDrive\桌面\面试题\CS Notes\进程状态.PNG) 

    

14. ####  什么是分页？

    把内存空间划分为大小相等且固定的块，作为主存的基本单位。

    程序存储在不同的页面中，页面又离散的分布在内存中，因此需要一个页表来记录映射关系，实现页号到物理块号的映射。

    访问分页系统中内存数据需要两次：

    1. 从内存中访问页表，从中找到指定的物理号，加上页内偏移得到实际物理地址

    2. 根据第一次物理地址访问内存取出数据

       

15. #### 什么是分段？

    分页是为了提高内存利用率，而分段是为了满足程序员在编写代码的时候的一些逻辑需求(比如数 据共享，数据保护，动态链接等)。 分段内存管理当中，地址是二维的，一维是段号，二维是段内地址；其中每个段的长度是不一样 的，而且每个段内部都是从0开始编址的。由于分段管理中，每个段内部是连续内存分配，但是段和段之间是离散分配的，因此也存在一个逻辑地址到物理地址的映射关系，相应的就是段表机制。

    

16. #### 分页和分段有什么区别

    1. 分页对程序员是透明的，但是分段需要程序员显式划分每个段。 
    2. 分页的地址空间是一维地址空间，分段是二维的。 
    3. 页的大小不可变，段的大小可以动态改变。 
    4. 分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。

    

17. #### 什么是交换空间

    操作系统把物理内存(physical RAM)分成一块一块的小内存，每一块内存被称为页(page)。当内存资源不足时，Linux把某些页的内容转移至硬盘上的一块空间上，以释放内存空间。

    硬盘上的那块空间叫做交换空间(swap space),而这一过程被称为交换(swapping)。物理内存和交换空间的总容量就是虚拟内存的可用容量。 

    用途： 物理内存不足时一些不常用的页可以被交换出去，腾给系统。 程序启动时很多内存页被用来初始化，之后便不再需要，可以交换出去。

    

18. #### 物理地址，逻辑地址，有效地址，线性地址，虚拟地址

    **物理地址**：内存中真正的地址，具有唯一性。不管哪种地址，最终都会映射为物理地址。 在实模式 下，段基址 + 段内偏移经过地址加法器的处理，经过地址总线传输，最终也会转换为物理地址 。 

    **线性地址：**保护模式下，段基址 + 段内偏移，不过此时的段基址不能称为真正的地址，而是会被称作为一个选择子的东西，选择子就是个索引，相当于数组的下标，通过这个索引能够在 GDT 中 找到相应的段描述符，段描述符记录了段的起始、段的大小等信息，这样便得到了基地址。如果此时没有开启内存分页功能，那么这个线性地址可以直接当做物理地址来使用，直接访问内存。

    **虚拟地址：**开启了分页功能的线性地址就是虚拟地址 

    **有效地址/逻辑地址：**不论在实模式还是保护模式下的段内偏移地址

    

19. #### 页面替换算法 

    ![页面替换算法](C:\Users\chens\OneDrive\桌面\面试题\CS Notes\页面替换算法.PNG)

    

20. #### 缓冲区溢出是什么？危害？

    计算机向缓冲区填充数据时超出了缓冲区本身的容量，溢出的数据覆盖在合法数据上

    1. 程序崩溃，拒绝服务
    2. 跳转并执行一段恶意代码

    溢出原因：程序中没有仔细检查用户输入

    

21. #### 虚拟内存

    虚拟内存就是说，让物理内存扩充成更大的<u>逻辑内存</u>，从而让程序获得更多的可用内存。虚拟内存使用<u>部分加载</u>的技术，让一个进程或者资源的某些页面加载进内存，从而能够加载更多的进程，甚至能加载比内存大的进程，这样看起来好像内存变大了，这部分内存其实包含了磁盘或者硬盘，并且就叫做虚拟内存。

    最好的算法是老化算法和WSClock算法。他们分别是基于 LRU 和工作集算法。他们都具有良好的性能 并且能够被有效的实现。还存在其他一些好的算法，但实际上这两个可能是最重要的。

    

22. #### 虚拟内存的实现方式

    1. 请求分页存储管理

    2. 请求分段存储管理

    3. 请求段页式存储管理 

       

23. #### IO多路复用

    IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程。

    IO多路复用适用如下场合： 

    1. 当客户处理多个描述字时（一般是交互式输入和网络套接口），必须使用I/O复用。 

    2. 当一个客户同时处理多个套接口时，而这种情况是可能的，但很少出现。 

    3. 如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I/O复用。 

    4. 如果一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用。 

    5. 如果一个服务器要处理多个服务或多个协议，一般要使用I/O复用。 

    6. 与多进程和多线程技术相比，I/O多路复用技术的最大优势是系统开销小，系统不必创建进程/线程，也不必维护这些进程/线程，从而大大减小了系统的开销。

       

24. #### 硬链接和软连接

    硬链接：就是在目录下创建一个条目，记录着文件名与 inode 编号，这个 inode 就是源文件的 inode 。删除任意一个条目，文件还是存在，只要引用数量不为 0 。但是硬链接有限制，它不能跨越文件系统，也不能对目录进行链接。 

    符号链接文件保存着源文件所在的绝对路径，在读取时会定位到源文件上，可以理解为 Windows 的快捷方式。当源文件被删除了，链接文件就打不开了。因为记录的是路径，所以可以为目录建立 符号链接。

    

25. #### 中断的处理过程

    1. 保护现场：将当前执行程序的相关数据保存在寄存器中，然后入栈。 
    2. 开中断：以便执行中断时能响应较高级别的中断请求。 
    3. 中断处理 
    4. 关中断：保证恢复现场时不被新中断打扰 
    5. 恢复现场：从堆栈中按序取出程序数据，恢复中断前的执行状态。

    

26. #### 中断和轮询有什么区别？

    1. 轮询：CPU对特定设备轮流询问。效率低等待时间长，CPU利用率不高

    2. 中断：通过特定事件提醒CPU。容易遗漏问题，CPU利用率不高

       

27. #### 用户态和内核态是如何切换的

    1. 首先用户程序会调用 glibc 库，glibc 是一个标准库，同时也是一套核心库，库中定义了很多关键 API。 

    2. glibc 库知道针对不同体系结构调用系统调用的正确方法，它会根据体系结构应用程序的二进制接口设置用户进程传递的参数，来准备系统调用。 

    3. 然后，glibc 库调用 软件中断指令(SWI) ，这个指令通过更新 CPSR 寄存器将模式改为超级用户模式，然后跳转到地址 0x08 处。 

    4. 到目前为止，整个过程仍处于用户态下，在执行 SWI 指令后，允许进程执行内核代码，MMU 现在允许内核虚拟内存访问从地址 0x08 开始，进程执行加载并跳转到中断处理程序，这个程序就是 ARM 中的 vector_swi()

    5. 在 vector_swi() 处，从 SWI 指令中提取系统调用号 SCNO，然后使用 SCNO 作为系统调用表 sys_call_table 的索引，调转到系统调用函数。 

    6. 执行系统调用完成后，将还原用户模式寄存器，然后再以用户模式执行

       

28. #### UNIX常见的IO模型

    对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内 核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段： 

    1. 等待数据准备就绪 (Waiting for the data to be ready) 
    2. 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process) 正式因为这两个阶段

    linux系统产生了下面五种网络模式的方案： 

    1. 阻塞式IO模型(blocking IO model) 
    2. 非阻塞式IO模型(noblocking IO model) 
    3. IO复用式IO模型(IO multiplexing model) 
    4. 信号驱动式IO模型(signal-driven IO model) 
    5. 异步IO式IO模型(asynchronous IO model) 

    对于这几种 IO 模型的详细说明，可以参考这篇文章：https://juejin.cn/post/6942686874301857800# heading-13 其中，IO多路复用模型指的是：使用单个进程同时处理多个网络连接IO，他的原理就是select、poll、 epoll 不断轮询所负责的所有 socket，当某个socket有数据到达了，就通知用户进程。该模型的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。

    

29. #### select, poll, epoll区别

    都是 IO 多路复用的机制。I/O 多路复用就是通过一种机制监视多个描述符， 一旦某个描述符就绪（读就绪或者写就绪），就通知程序进行相应的读写操作。但 select， poll，epoll 本质上都是同步 I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说读写过程是阻塞的，而异步 I/O 则无需自己负责进行读写，异步 I/O 的实现会负责把数据从内 核拷贝到用户空间。

    1. select:：时间复杂度O(n)

       仅仅知道有IO事件发生，但并不知道是哪几个流，只能无差别轮询所有流，找出能读出数据或写入数据的流，并对其进行操作。

    2. poll：时间复杂度O(n)

       将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态。

       与select相比没有**最大连接数的限制**，原因是基于链表来存储的

    3. epoll：时间复杂度O(1)

       epoll会把哪个流发生了怎样的IO**事件**通知我们，事件驱动。

    